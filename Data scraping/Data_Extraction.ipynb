{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AI/ML Coding Round\n",
    "### Problem: \n",
    "Train a LLM that can answer queries about JFrog Pipelines' [native steps](https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps). \n",
    "When posed with a question like \"How do I upload an artifact?\" or \"What step should I use for an Xray scan?\", the model should list the appropriate native step(s) and provide an associated YAML for that step.\n",
    "\n",
    " ### Requirements\n",
    "1. Data Collection: Acquire publicly available information on Native Steps from JFrog's website that contain information on native steps for building pipelines. Data that is not publicly accessible falls outside the scope of this coding challenge. (https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps)\n",
    "2. Data Preprocessing: Process the text to make it suitable for training. This might involve tokenization, stemming, and other NLP techniques.\n",
    "3. Model Training: Train a LLM on the (preprocessed) dataset. You can choose one of the freely available open source model like BERT or any other model available\n",
    "4. Query Handling: Implement a function that takes a user query as input and returns the appropriate native step(s) and a sample YAML configuration.\n",
    "5. YAML Generation: Implement a function that can generate a sample YAML configuration based on the identified native step(s).\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@author - Midhun Kumar\n",
    "@email  - midhunkumar04@agmail.com\n",
    "```\n",
    "-----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data scraping and preparation\n",
    "\n",
    "\n",
    "#### Data Understanding\n",
    "1. I have started exploring the documentation sites given in the problem and noted the below points.\n",
    "    - The site has multiple navigation links for various pipline procedures.\n",
    "    - Each discipline procedure has two main things, like instructions and yaml pipline exampls we can use them for training\n",
    "    - If we can extract these links, we can use them to scrape the data from each document and use them for preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1 Link Extraction\n",
    " -  Extarcting the pipeline documentaion links from following site \n",
    "https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries for link extraction\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import requests\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link extraction function\n",
    "def linkExtarction(url:str) -> list:\n",
    "    '''\n",
    "    This function takes url:str as input and retrun list of link in the site\n",
    "    '''\n",
    "    result = requests.get(url)\n",
    "    scrapedData = soup(result.content)\n",
    "    links =  scrapedData.select('a')\n",
    "    return [link['href'] for link in links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://jfrog.com/help/r/jfrog-pipelines-documentation',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/jfrog-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-use-cases',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-concepts',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-step-by-step',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/see-it-live',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-quickstart',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-example-hello-world',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-example-docker-build-and-push',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-example-release-to-edge-node',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-example-go-build',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-example-npm-build',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-example-maven-build',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-example-helm-blue-green-deploy',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/configuring-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/managing-pipelines-integrations',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/managing-pipeline-sources',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-source-sync-recovery',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/managing-pipelines-node-pools',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-custom-vm-images',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-dynamic-nodes-on-kubernetes',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/managing-pipelines-static-nodes',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/sending-pipelines-nodes-agent-logs-to-logstash',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/defining-a-pipeline',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-integrations',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/airbrake-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/artifactory-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/aws-keys-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/azure-keys-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/digital-ocean-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/bitbucket-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/bitbucket-server-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/distribution-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/docker-registry-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/file-server-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/generic-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/github-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/github-enterprise-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gitlab-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/google-cloud-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/jenkins-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/jenkins-server-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/jfrog-platform-access-token-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/jira-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/incoming-webhook-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/kubernetes-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/newrelic-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/outgoing-webhook-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pagerduty-events-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pem-key-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/slack-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/smtp-credentials-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/ssh-key-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-resources',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-resources',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/using-resources',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/viewing-resources-in-the-ui',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/advanced-usage-of-resources',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/aql',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/artifact',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/buildinfo',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/crontrigger',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/distributionrule',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/filespec',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gitrepo',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helmchart',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/image',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/incomingwebhook',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/outgoingwebhook',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/propertybag',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/releasebundle',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/remotefile',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/vmcluster',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/bash',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/createreleasebundle',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/distributereleasebundle',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/dockerpush',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/dockerbuild',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gobuild',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gopublishbinary',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gopublishmodule',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gradlebuild',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helmbluegreencleanup',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helmbluegreendeploy',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helmbluegreenroleswitch',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helmdeploy',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helmpublish',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/jenkins',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/linuxvmdeploy',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/matrix',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/mvnbuild',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/npmbuild',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/npmpublish',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/prematrix',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/postmatrix',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/powershell',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/promotebuild',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/publishbuildinfo',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/signreleasebundle',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/triggerpipeline',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/uploadartifact',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/xrayscan',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-utility-functions',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/bump_semver',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/replace_envs',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/retry_command',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/get_uuid',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/save_artifact_info',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/validate_artifact',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/configure_jfrog_cli',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/use_jfrog_cli',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/check_xray_available',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/cleanup_jfrog_cli',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/set_trigger_payload',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/get_trigger_payload',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/end_step',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/update_run_description',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/set_run_name',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/source-control',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/compare_git',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/update_commit_status',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/test-reports',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/encryption',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/encrypt_string',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/decrypt_string',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/encrypt_file',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/decrypt_file',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/notifications',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/json',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/set_payload',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/read_json',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/resources',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/replicate_resource',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/write_output',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/caching',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/add_cache_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/restore_cache_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/run-state-management',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/add_run_variables',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/export_run_variables',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/add_run_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/restore_run_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/affinity-group-state-management',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/add_affinity_group_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/restore_affinity_group_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-state-management',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/add_pipeline_variables',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/export_pipeline_variables',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/add_pipeline_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/restore_pipeline_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/step-properties',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/find_resource_variable',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/get_integration_name',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/get_resource_name',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/get_resource_names',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/get_affinity_group_step_names',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/find_step_configuration_value',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-environment-variables',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-templates',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/global-templates',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helloworld',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/goci',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gradleci',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/mavenci',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/npmci',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/promoteci',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/dockerbuildandpush',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helmpublishanddeploy',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/artifactory-artifact-cleanup-template-1.40-and-higher',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/using-global-templates-to-create-a-pipeline-source-1.31-and-higher',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/using-global-templates-to-create-a-pipeline-source-1.30-and-lower',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/system-templates',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/local-templates',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/managing-pipelines-templates',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-tasks',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/build-publish',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/curate-artifact',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/email-notify',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/frogbot',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/0.1.0',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/0.0.3',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/go-build',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/go-security-check',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/go-static-check',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/0.1.0',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/0.0.2',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gradle-build',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/jira-comment',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/mvn-build',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/npm-build',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/run-cypress',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setup-go',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/0.1.0',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/0.0.3',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setup-java',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setup-jfrog-cli',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setup-node',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setup-yarn',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/slack-notify',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/upload-file-to-s3',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/extending-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-extension-expressions',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-extension-resource-model',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-extension-step-model',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-extension-usage',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-extensions-tutorial',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/managing-pipelines-extensions',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/working-with-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-history',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-run-logs',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/running-a-pipeline',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/using-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/breaking-your-pipelines-into-steps',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/triggering-pipelines-and-steps',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-stateful-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/inserting-secrets-in-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/running-multiple-steps-on-the-same-build-node',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/sending-notifications-from-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-jira-issues-from-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/sending-build-status-to-source-control',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/recording-unit-test-results',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/deploying-to-kubernetes-in-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setting-up-maven-builds-for-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/caching-step-runtimes',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-multibranch-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/using-jenkins-with-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/using-the-matrix-step',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setting-retention-policy',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/signed-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setting-step-timeouts',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/speeding-up-pipeline-runs',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/triggering-a-run-with-custom-parameters',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/adding-build-badges',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/conditional-workflows',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/approval-gates',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-of-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/embedded-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/monitoring-pipelines-using-new-relic-apm',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/managing-runtimes',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/choosing-your-runtime-image',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/running-steps-on-the-host',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/choosing-node-pools',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/runtime-images',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/t~ovaki5HJDlhSI8nUZZow',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/cvMvKDVFYgYz9CAEi5V0DQ',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/JuhAfy2o9I7WDuzDyPjI~w',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/1yeQM4x8WIlvqW5PjuzmRA',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/pqNZFdHirwvJ8kqjZPY46w',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/CMyzVpgNkZRhMCAGBV3WUQ',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/CBbQUEleXOAdEK~sv3QSIg',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/ahbSstb2sYifVdbqlJb6pA',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/eeCPdY_CZTbOtlPJzrgVaw',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/E5HPgKlVIduhL9KURYCrxg',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/YWv9eZVG2Q4SzRQ_N8wxxw',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/f39y1WcXkTQLusVmwu52uA',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/OU14OBJ_4faErvHbd2e2Bg',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/X1WU_5tNPs67bGBUBcT8rw',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/ULtmnqkvN~7OS8gReJZ55w',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/P1nvfSf9oV0MY3jJGqMB_g',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/s699hxjWCdbiUVf3JZ4NLA',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/MD44zUcLMbxgNISASufU6w',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/gvScchJe4eqc1uM4mfO7Ew',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/5Ojvui6F1kvxnuzQWGAX_A',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/44OkpN_tMlW1tYfk2qwhBg',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/kCuBcVFDeWF6DgSXQWFLjA',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/aOosLRoIFNB4e8I37qWbEQ',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/qjLtCJG9k5z3SIVWUyEMBQ',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/kohJX4jGwXj9k60unPZ2wA',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/l~EJ8fnn2GqxVyHQ4FL1Cg',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/IHsC7xFESYudBr8ySwl9_w',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/IUOnljlIKRF1wUOXmwAZnQ',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/9bmEZe6zWZ9mtGP6qMkEvA',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/F8LwLNYebdJmDfy4L1jpNw',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/CzSwCXjPoLMY3gwig81pog',\n",
      " 'https://pipelines.jfrog.io/ui/pipelines/myPipelines/viewPipelines',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/eJJdeVT9Cq2zK4TzJpEaOg?section=UUID-c9f2a58e-267d-94f7-b9df-1458c35267da_Generic',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/JuhAfy2o9I7WDuzDyPjI~w',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/qjLtCJG9k5z3SIVWUyEMBQ',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/eJJdeVT9Cq2zK4TzJpEaOg?section=UUID-c9f2a58e-267d-94f7-b9df-1458c35267da_id_PipelinesSteps-nativeNativeSteps',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/JuhAfy2o9I7WDuzDyPjI~w',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/gvScchJe4eqc1uM4mfO7Ew',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/aOosLRoIFNB4e8I37qWbEQ',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/qjLtCJG9k5z3SIVWUyEMBQ',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/kohJX4jGwXj9k60unPZ2wA',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/1yeQM4x8WIlvqW5PjuzmRA',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/pqNZFdHirwvJ8kqjZPY46w',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/CMyzVpgNkZRhMCAGBV3WUQ',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/CBbQUEleXOAdEK~sv3QSIg',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/ahbSstb2sYifVdbqlJb6pA',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/eeCPdY_CZTbOtlPJzrgVaw',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/E5HPgKlVIduhL9KURYCrxg',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/ahbSstb2sYifVdbqlJb6pA',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/YWv9eZVG2Q4SzRQ_N8wxxw',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/f39y1WcXkTQLusVmwu52uA',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/OU14OBJ_4faErvHbd2e2Bg',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/X1WU_5tNPs67bGBUBcT8rw',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/ULtmnqkvN~7OS8gReJZ55w',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/P1nvfSf9oV0MY3jJGqMB_g',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/s699hxjWCdbiUVf3JZ4NLA',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/5Ojvui6F1kvxnuzQWGAX_A',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/44OkpN_tMlW1tYfk2qwhBg',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/kCuBcVFDeWF6DgSXQWFLjA',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/l~EJ8fnn2GqxVyHQ4FL1Cg',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/IHsC7xFESYudBr8ySwl9_w',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/IUOnljlIKRF1wUOXmwAZnQ',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/CzSwCXjPoLMY3gwig81pog',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/eJJdeVT9Cq2zK4TzJpEaOg?section=UUID-c9f2a58e-267d-94f7-b9df-1458c35267da_id_PipelinesSteps-stepsGenericandNativeSteps',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/eJJdeVT9Cq2zK4TzJpEaOg?section=UUID-c9f2a58e-267d-94f7-b9df-1458c35267da_id_PipelinesSteps-Environmentvariables',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/eJJdeVT9Cq2zK4TzJpEaOg?section=UUID-c9f2a58e-267d-94f7-b9df-1458c35267da_id_PipelinesSteps-Runtime',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/eJJdeVT9Cq2zK4TzJpEaOg?section=UUID-c9f2a58e-267d-94f7-b9df-1458c35267da_id_PipelinesSteps-NodePoolAssignment',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/eJJdeVT9Cq2zK4TzJpEaOg?section=UUID-c9f2a58e-267d-94f7-b9df-1458c35267da_id_PipelinesSteps-AffinityGroup',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/eJJdeVT9Cq2zK4TzJpEaOg?section=UUID-c9f2a58e-267d-94f7-b9df-1458c35267da_id_PipelinesSteps-QueuingPriority',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/eJJdeVT9Cq2zK4TzJpEaOg?section=UUID-c9f2a58e-267d-94f7-b9df-1458c35267da_id_PipelinesSteps-TimeoutDuration',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/eJJdeVT9Cq2zK4TzJpEaOg?section=UUID-c9f2a58e-267d-94f7-b9df-1458c35267da_id_PipelinesSteps-Integrations',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/eJJdeVT9Cq2zK4TzJpEaOg?section=UUID-c9f2a58e-267d-94f7-b9df-1458c35267da_id_PipelinesSteps-InputsTriggers',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/eJJdeVT9Cq2zK4TzJpEaOg?section=UUID-c9f2a58e-267d-94f7-b9df-1458c35267da_id_PipelinesSteps-Outputs',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/7yJX~hEQVTb4TOBzmNbSVQ',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/CMyzVpgNkZRhMCAGBV3WUQ',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/CBbQUEleXOAdEK~sv3QSIg',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/WSVzs0FbTFmdWbWseh45_w',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/UBYixse92Dy~zOMXKvQkVA',\n",
      " 'urn:resource:component:362369',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/bYG9ddsey0Deno5UB6mlQg',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/JuhAfy2o9I7WDuzDyPjI~w',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/NDuFP7O7YmF1UrYCIbvuHg',\n",
      " 'https://jfrog.com/help/r/2zMh0nFOk9FPLZNgd37bwg/PfQ_oIQbrM7fhWxR1Hmstw',\n",
      " 'https://jfrog.com/help/']\n"
     ]
    }
   ],
   "source": [
    "# verifying the links\n",
    "url = 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps'\n",
    "links = linkExtarction(url)\n",
    "pprint(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "- From the above results, we can see we have extracted all the links from the site.\n",
    "- We can also observe that many links do not have proper naming conventions, so we are going to focus on only the links with proper naming so that we can use them to label the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Filtering only required links \n",
    "'''\n",
    "import re # importing regex for string matching\n",
    "\n",
    "def filter_links(links:list)->list:\n",
    "    ''' \n",
    "    This function will take list of links and return filter list based on condition\n",
    "    '''\n",
    "    filterd_links = []\n",
    "    for link in links:\n",
    "        matchString = 'https://jfrog.com/help/r/jfrog-pipelines-documentation/'\n",
    "        if re.search(matchString,link):\n",
    "            filterd_links.append(link)\n",
    "    return filterd_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://jfrog.com/help/r/jfrog-pipelines-documentation/jfrog-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-use-cases',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-concepts',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-step-by-step',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/see-it-live',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-quickstart',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-example-hello-world',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-example-docker-build-and-push',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-example-release-to-edge-node',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-example-go-build',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-example-npm-build',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-example-maven-build',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-example-helm-blue-green-deploy',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/configuring-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/managing-pipelines-integrations',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/managing-pipeline-sources',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-source-sync-recovery',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/managing-pipelines-node-pools',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-custom-vm-images',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-dynamic-nodes-on-kubernetes',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/managing-pipelines-static-nodes',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/sending-pipelines-nodes-agent-logs-to-logstash',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/defining-a-pipeline',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-integrations',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/airbrake-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/artifactory-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/aws-keys-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/azure-keys-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/digital-ocean-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/bitbucket-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/bitbucket-server-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/distribution-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/docker-registry-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/file-server-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/generic-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/github-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/github-enterprise-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gitlab-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/google-cloud-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/jenkins-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/jenkins-server-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/jfrog-platform-access-token-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/jira-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/incoming-webhook-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/kubernetes-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/newrelic-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/outgoing-webhook-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pagerduty-events-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pem-key-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/slack-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/smtp-credentials-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/ssh-key-integration',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-resources',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-resources',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/using-resources',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/viewing-resources-in-the-ui',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/advanced-usage-of-resources',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/aql',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/artifact',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/buildinfo',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/crontrigger',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/distributionrule',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/filespec',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gitrepo',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helmchart',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/image',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/incomingwebhook',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/outgoingwebhook',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/propertybag',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/releasebundle',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/remotefile',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/vmcluster',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/bash',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/createreleasebundle',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/distributereleasebundle',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/dockerpush',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/dockerbuild',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gobuild',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gopublishbinary',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gopublishmodule',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gradlebuild',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helmbluegreencleanup',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helmbluegreendeploy',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helmbluegreenroleswitch',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helmdeploy',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helmpublish',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/jenkins',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/linuxvmdeploy',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/matrix',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/mvnbuild',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/npmbuild',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/npmpublish',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/prematrix',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/postmatrix',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/powershell',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/promotebuild',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/publishbuildinfo',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/signreleasebundle',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/triggerpipeline',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/uploadartifact',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/xrayscan',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-utility-functions',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/bump_semver',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/replace_envs',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/retry_command',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/get_uuid',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/save_artifact_info',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/validate_artifact',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/configure_jfrog_cli',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/use_jfrog_cli',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/check_xray_available',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/cleanup_jfrog_cli',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/set_trigger_payload',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/get_trigger_payload',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/end_step',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/update_run_description',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/set_run_name',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/source-control',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/compare_git',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/update_commit_status',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/test-reports',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/encryption',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/encrypt_string',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/decrypt_string',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/encrypt_file',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/decrypt_file',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/notifications',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/json',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/set_payload',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/read_json',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/resources',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/replicate_resource',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/write_output',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/caching',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/add_cache_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/restore_cache_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/run-state-management',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/add_run_variables',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/export_run_variables',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/add_run_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/restore_run_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/affinity-group-state-management',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/add_affinity_group_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/restore_affinity_group_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-state-management',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/add_pipeline_variables',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/export_pipeline_variables',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/add_pipeline_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/restore_pipeline_files',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/step-properties',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/find_resource_variable',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/get_integration_name',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/get_resource_name',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/get_resource_names',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/get_affinity_group_step_names',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/find_step_configuration_value',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-environment-variables',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-templates',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/global-templates',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helloworld',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/goci',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gradleci',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/mavenci',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/npmci',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/promoteci',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/dockerbuildandpush',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/helmpublishanddeploy',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/artifactory-artifact-cleanup-template-1.40-and-higher',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/using-global-templates-to-create-a-pipeline-source-1.31-and-higher',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/using-global-templates-to-create-a-pipeline-source-1.30-and-lower',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/system-templates',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/local-templates',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/managing-pipelines-templates',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-tasks',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/build-publish',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/curate-artifact',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/email-notify',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/frogbot',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/0.1.0',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/0.0.3',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/go-build',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/go-security-check',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/go-static-check',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/0.1.0',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/0.0.2',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/gradle-build',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/jira-comment',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/mvn-build',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/npm-build',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/run-cypress',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setup-go',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/0.1.0',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/0.0.3',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setup-java',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setup-jfrog-cli',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setup-node',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setup-yarn',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/slack-notify',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/upload-file-to-s3',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/extending-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-extension-expressions',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-extension-resource-model',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-extension-step-model',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-extension-usage',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-extensions-tutorial',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/managing-pipelines-extensions',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/working-with-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-history',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-run-logs',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/running-a-pipeline',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/using-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/breaking-your-pipelines-into-steps',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/triggering-pipelines-and-steps',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-stateful-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/inserting-secrets-in-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/running-multiple-steps-on-the-same-build-node',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/sending-notifications-from-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-jira-issues-from-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/sending-build-status-to-source-control',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/recording-unit-test-results',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/deploying-to-kubernetes-in-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setting-up-maven-builds-for-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/caching-step-runtimes',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-multibranch-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/using-jenkins-with-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/using-the-matrix-step',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setting-retention-policy',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/signed-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/setting-step-timeouts',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/speeding-up-pipeline-runs',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/triggering-a-run-with-custom-parameters',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/adding-build-badges',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/conditional-workflows',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/approval-gates',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipeline-of-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/embedded-pipelines',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/monitoring-pipelines-using-new-relic-apm',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/managing-runtimes',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/choosing-your-runtime-image',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/running-steps-on-the-host',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/choosing-node-pools',\n",
      " 'https://jfrog.com/help/r/jfrog-pipelines-documentation/runtime-images']\n"
     ]
    }
   ],
   "source": [
    "pprint(filter_links(links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reamrks:\n",
    "- We have filterd all the required links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2 Now will work on data extarction for each link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Creating Dynamic Nodes on Kubernetes\n",
      "## JFrog Pipelines Documentation\n",
      "ft:sourceType\n",
      "    Paligo\n",
      "  * JFrog Pipelines\n",
      "  * Pipelines Use Cases\n",
      "  * Pipelines Concepts\n",
      "  * Pipelines Step-By-Step\n",
      "  * See it Live\n",
      "  * Pipelines Quickstart\n",
      "  * Pipeline Example: Hello World\n",
      "  * Pipeline Example: Docker Build and Push\n",
      "  * Pipeline Example: Release to Edge Node\n",
      "  * Pipeline Example: Go Build\n",
      "  * Pipeline Example: Npm Build\n",
      "  * Pipeline Example: Maven Build\n",
      "  * Pipeline Example: Helm Blue-Green Deploy\n",
      "  * Configuring Pipelines\n",
      "  * Managing Pipelines Integrations\n",
      "  * Managing Pipeline Sources\n",
      "  * Pipeline Source Sync Recovery\n",
      "  * Managing Pipelines Node Pools\n",
      "  * Creating Custom VM Images\n",
      "  * Creating Dynamic Nodes on Kubernetes\n",
      "  * Managing Pipelines Static Nodes\n",
      "  * Sending Pipelines Nodes Agent Logs to Logstash\n",
      "  * Creating Pipelines\n",
      "  * Defining a Pipeline\n",
      "  * Pipelines Integrations\n",
      "  * Airbrake Integration\n",
      "  * Artifactory Integration\n",
      "  * AWS Keys Integration\n",
      "  * Azure Keys Integration\n",
      "  * Digital Ocean Integration\n",
      "  * Bitbucket Integration\n",
      "  * Bitbucket Server Integration\n",
      "  * Distribution Integration\n",
      "  * Docker Registry Integration\n",
      "  * File Server Integration\n",
      "  * Generic Integration\n",
      "  * GitHub Integration\n",
      "  * GitHub Enterprise Integration\n",
      "  * GitLab Integration\n",
      "  * Google Cloud Integration\n",
      "  * Jenkins Integration\n",
      "  * Jenkins Server Integration\n",
      "  * JFrog Platform Access Token Integration\n",
      "  * Jira Integration\n",
      "  * Incoming Webhook Integration\n",
      "  * Kubernetes Integration\n",
      "  * NewRelic Integration\n",
      "  * Outgoing Webhook Integration\n",
      "  * PagerDuty Events Integration\n",
      "  * PEM Key Integration\n",
      "  * Slack Integration\n",
      "  * SMTP Credentials Integration\n",
      "  * SSH Key Integration\n",
      "  * Pipelines Resources\n",
      "  * Creating Resources\n",
      "  * Using Resources\n",
      "  * Viewing Resources in the UI\n",
      "  * Advanced Usage of Resources\n",
      "  * Aql\n",
      "  * Artifact\n",
      "  * BuildInfo\n",
      "  * CronTrigger\n",
      "  * DistributionRule\n",
      "  * FileSpec\n",
      "  * GitRepo\n",
      "  * HelmChart\n",
      "  * Image\n",
      "  * IncomingWebhook\n",
      "  * OutgoingWebhook\n",
      "  * PropertyBag\n",
      "  * ReleaseBundle\n",
      "  * RemoteFile\n",
      "  * VmCluster\n",
      "  * Pipelines Steps\n",
      "  * Bash\n",
      "  * CreateReleaseBundle\n",
      "  * DistributeReleaseBundle\n",
      "  * DockerPush\n",
      "  * DockerBuild\n",
      "  * GoBuild\n",
      "  * GoPublishBinary\n",
      "  * GoPublishModule\n",
      "  * GradleBuild\n",
      "  * HelmBlueGreenCleanup\n",
      "  * HelmBlueGreenDeploy\n",
      "  * HelmBlueGreenRoleSwitch\n",
      "  * HelmDeploy\n",
      "  * HelmPublish\n",
      "  * Jenkins\n",
      "  * LinuxVMDeploy\n",
      "  * Matrix\n",
      "  * MvnBuild\n",
      "  * NpmBuild\n",
      "  * NpmPublish\n",
      "  * PreMatrix\n",
      "  * PostMatrix\n",
      "  * PowerShell\n",
      "  * PromoteBuild\n",
      "  * PublishBuildInfo\n",
      "  * SignReleaseBundle\n",
      "  * TriggerPipeline\n",
      "  * UploadArtifact\n",
      "  * XrayScan\n",
      "  * Pipelines Utility Functions\n",
      "  * bump_semver\n",
      "  * replace_envs\n",
      "  * retry_command\n",
      "  * get_uuid\n",
      "  * save_artifact_info\n",
      "  * validate_artifact\n",
      "  * configure_jfrog_cli\n",
      "  * use_jfrog_cli\n",
      "  * check_xray_available\n",
      "  * cleanup_jfrog_cli\n",
      "  * set_trigger_payload\n",
      "  * get_trigger_payload\n",
      "  * end_step\n",
      "  * update_run_description\n",
      "  * set_run_name\n",
      "  * Source Control\n",
      "  * compare_git\n",
      "  * update_commit_status\n",
      "  * Test Reports\n",
      "  * Encryption\n",
      "  * encrypt_string\n",
      "  * decrypt_string\n",
      "  * encrypt_file\n",
      "  * decrypt_file\n",
      "  * Notifications\n",
      "  * JSON\n",
      "  * set_payload\n",
      "  * read_json\n",
      "  * Resources\n",
      "  * replicate_resource\n",
      "  * write_output\n",
      "  * Caching\n",
      "  * add_cache_files\n",
      "  * restore_cache_files\n",
      "  * Run State Management\n",
      "  * add_run_variables\n",
      "  * export_run_variables\n",
      "  * add_run_files\n",
      "  * restore_run_files\n",
      "  * Affinity Group State Management\n",
      "  * add_affinity_group_files\n",
      "  * restore_affinity_group_files\n",
      "  * Pipeline State Management\n",
      "  * add_pipeline_variables\n",
      "  * export_pipeline_variables\n",
      "  * add_pipeline_files\n",
      "  * restore_pipeline_files\n",
      "  * Step Properties\n",
      "  * find_resource_variable\n",
      "  * get_integration_name\n",
      "  * get_resource_name\n",
      "  * get_resource_names\n",
      "  * get_affinity_group_step_names\n",
      "  * find_step_configuration_value\n",
      "  * Pipelines Environment Variables\n",
      "  * Pipelines Templates\n",
      "  * Global Templates\n",
      "  * HelloWorld\n",
      "  * GoCI\n",
      "  * GradleCI\n",
      "  * MavenCI\n",
      "  * NpmCI\n",
      "  * PromoteCI\n",
      "  * DockerBuildAndPush\n",
      "  * HelmPublishAndDeploy\n",
      "  * Artifactory Artifact Cleanup Template (1.40 and higher)\n",
      "  * Using Global Templates to Create a Pipeline Source (1.31 and higher)\n",
      "  * Using Global Templates to Create a Pipeline Source (1.30 and lower)\n",
      "  * System Templates\n",
      "  * Local Templates\n",
      "  * Managing Pipelines Templates\n",
      "  * Pipelines Tasks\n",
      "  * build-publish\n",
      "  * curate-artifact\n",
      "  * email-notify\n",
      "  * frogbot\n",
      "  * 0.1.0\n",
      "  * 0.0.3\n",
      "  * go-build\n",
      "  * go-security-check\n",
      "  * go-static-check\n",
      "  * 0.1.0\n",
      "  * 0.0.2\n",
      "  * gradle-build\n",
      "  * jira-comment\n",
      "  * mvn-build\n",
      "  * npm-build\n",
      "  * run-cypress\n",
      "  * setup-go\n",
      "  * 0.1.0\n",
      "  * 0.0.3\n",
      "  * setup-java\n",
      "  * setup-jfrog-cli\n",
      "  * setup-node\n",
      "  * setup-yarn\n",
      "  * slack-notify\n",
      "  * upload-file-to-s3\n",
      "  * Extending Pipelines\n",
      "  * Pipelines Extension Expressions\n",
      "  * Pipelines Extension Resource Model\n",
      "  * Pipelines Extension Step Model\n",
      "  * Pipelines Extension Usage\n",
      "  * Pipelines Extensions Tutorial\n",
      "  * Managing Pipelines Extensions\n",
      "  * Working with Pipelines\n",
      "  * Pipeline History\n",
      "  * Pipeline Run Logs\n",
      "  * Running a Pipeline\n",
      "  * Using Pipelines\n",
      "  * Breaking Your Pipelines into Steps\n",
      "  * Triggering Pipelines and Steps\n",
      "  * Creating Stateful Pipelines\n",
      "  * Inserting Secrets in Pipelines\n",
      "  * Running Multiple Steps on the Same Build Node\n",
      "  * Sending Notifications from Pipelines\n",
      "  * Creating Jira Issues From Pipelines\n",
      "  * Sending Build Status to Source Control\n",
      "  * Recording Unit Test Results\n",
      "  * Deploying to Kubernetes in Pipelines\n",
      "  * Setting Up Maven Builds for Pipelines\n",
      "  * Caching Step Runtimes\n",
      "  * Creating Multibranch Pipelines\n",
      "  * Using Jenkins With Pipelines\n",
      "  * Using the Matrix Step\n",
      "  * Setting Retention Policy\n",
      "  * Signed Pipelines\n",
      "  * Setting Step Timeouts\n",
      "  * Speeding up Pipeline Runs\n",
      "  * Triggering a Run with Custom Parameters\n",
      "  * Adding Build Badges\n",
      "  * Conditional Workflows\n",
      "  * Approval Gates\n",
      "  * Pipeline of Pipelines\n",
      "  * Embedded Pipelines\n",
      "  * Monitoring Pipelines using New Relic APM\n",
      "  * Managing Runtimes\n",
      "  * Choosing your Runtime Image\n",
      "  * Running Steps on the Host\n",
      "  * Choosing Node Pools\n",
      "  * Runtime Images\n",
      "\n",
      "\n",
      "This tutorial explains how to specify a kubeconfig for a Kubernetes Integration to authenticate to a self-hosted Kubernetes cluster for a dynamic node pool. You can use a cloud provider solution like EKS, GKE, or AKS, or a self-hosted Kubernetes solution.\n",
      "This tutorial assumes that you have working knowledge of Docker and Kubernetes and understand the following concepts:\n",
      "  * Self hosting on GCP\n",
      "  * Self hosting on AWS\n",
      "  * kubeconfig files\n",
      "  * Configuring Service Accounts\n",
      "\n",
      "\n",
      "##### Configure a Kubernetes Service Account\n",
      "You must  configure a service account in Kubernetes to provide an identity for the build node processes that Pipelines will dynamically control.\n",
      "This procedure will use your personal account to create the service account. Make sure your personal account has permissions to do this.\n",
      "###### Verify Access to the Cluster\n",
      "First, make sure you can authenticate yourself to the cluster. This means you have a kubeconfig file that uses your personal account. You can verify this by running this command on your local machine and you should see the file listed.\n",
      "[code]\n",
      "    ls -al $HOME/.kube\n",
      "[/code]\n",
      " **Author a service account spec**\n",
      "To create a service account on Kubernetes, you can leverage `kubectl` and a service account spec. Create a YML file similar to the one below:\n",
      " **pipelines_k8s_sa.yml**\n",
      "[code]\n",
      "    apiVersion: v1\n",
      "    kind: ServiceAccount\n",
      "    metadata:\n",
      "      name: pipelines-k8s-pool   # <-- any name you'd like\n",
      "      namespace: jfrog           # <-- the cluster namespace\n",
      "[/code]\n",
      "###### Create the service account\n",
      "You can create a service account by running the following command:\n",
      "[code]\n",
      "    kubectl apply -f pipelines_k8s_sa.yaml\n",
      "[/code]\n",
      "##### Manually Create a Long-lived API Token for a ServiceAccount\n",
      "### Note\n",
      "Perform these steps if you are using Kubernetes 1.22 or higher, as these versions do not automatically create long-lived tokens. Versions of Kubernetes before v1.22 automatically created long term credentials for accessing the Kubernetes API.\n",
      "If you want to obtain an API token for a ServiceAccount, you create a new Secret with a special annotation, `kubernetes.io/service-account.name`.\n",
      "[code]\n",
      "    kubectl apply -f - <<EOF\n",
      "    apiVersion: v1\n",
      "    kind: Secret\n",
      "    metadata:\n",
      "      name: pipelines-k8s-pool\n",
      "      annotations:\n",
      "        kubernetes.io/service-account.name: pipelines-k8s-pool\n",
      "    type: kubernetes.io/service-account-token\n",
      "    EOF\n",
      "[/code]\n",
      "If you view the Secret using:\n",
      "`kubectl get secret/pipelines-k8s-pool -o yaml`\n",
      "you can see that the Secret now contains an API token for the \"`pipelines-k8s-pool`\" ServiceAccount.\n",
      "Because of the annotation you set, the control plane automatically generates a token for that ServiceAccounts, and stores them into the associated Secret. The control plane also cleans up tokens for deleted ServiceAccounts.\n",
      "`kubectl describe secrets/pipelines-k8s-pool`\n",
      "The output is similar to this:\n",
      "[code]\n",
      "    Name:           pipelines-k8s-pool\n",
      "    Namespace:      default\n",
      "    Labels:         <none>\n",
      "    Annotations:    kubernetes.io/service-account.name: pipelines-k8s-pool\n",
      "                    kubernetes.io/service-account.uid: da68f9c6-9d26-11e7-b84e-002dc52800da\n",
      "    \n",
      "    Type:   kubernetes.io/service-account-token\n",
      "    \n",
      "    Data\n",
      "    ====\n",
      "    ca.crt:         1338 bytes\n",
      "    namespace:      7 bytes\n",
      "    token:          ...\n",
      "[/code]\n",
      "When you delete a ServiceAccount that has an associated Secret, the Kubernetes control plane automatically cleans up the long-lived token from that Secret.\n",
      "##### Get Tokens and IP from Kubernetes\n",
      "Once the service account has been created, you will need to retrieve some key information from Kubernetes in order to configure it through a kubeconfig.\n",
      "###### Fetch the name of the secrets used by the service account\n",
      "This can be found by running the following command:\n",
      "[code]\n",
      "    kubectl describe serviceAccounts pipelines-k8s-pool\n",
      "[/code]\n",
      " **output**\n",
      "[code]\n",
      "    Name:               pipelines-k8s-pool\n",
      "    Namespace:          jfrog\n",
      "    Labels:             <none>\n",
      "    Annotations:        <none>\n",
      "    \n",
      "    Image pull secrets: <none>\n",
      "    Mountable secrets:  pipelines-k8s-pool-token-h6pdj\n",
      "    Tokens:             pipelines-k8s-pool-token-h6pdj\n",
      "[/code]\n",
      "Note the `Mountable secrets` string. This is the name of the secret that holds the token, and will be used in the next step. Or if you are on a later version of k8s, describe the secret you created in the last step.\n",
      "###### Fetch the token from the secret\n",
      "Using the `Mountable secrets` string, you can get the token used by the service account. Run the following command to extract this information:\n",
      "[code]\n",
      "    kubectl describe secrets pipelines-k8s-pool-token-h6pdj\n",
      "[/code]\n",
      " **output**\n",
      "[code]\n",
      "    Name:           pipelines-k8s-pool\n",
      "    Namespace:      jfrog\n",
      "    Labels:         <none>\n",
      "    Annotations:    kubernetes.io/service-account.name=pipelines-k8s-pool\n",
      "            kubernetes.io/service-account.uid=c2117d8e-3c2d-11e8-9ccd-42010a8a012f\n",
      "    \n",
      "    Type:   kubernetes.io/service-account-token\n",
      "    \n",
      "    Data\n",
      "    ====\n",
      "    ca.crt:     1115 bytes\n",
      "    namespace:  7 bytes\n",
      "    token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6InNoaXBwYWJsZS1kZXBsb3ktdG9rZW4tN3Nwc2oiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoic2hpcHBhYmxlLWRlcGxveSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImMyMTE3ZDhlLTNjMmQtMTFlOC05Y2NkLTQyMDEwYThhMDEyZiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpkZWZhdWx0OnNoaXBwYWJsZS1kZXBsb3kifQ.ZWKrKdpK7aukTRKnB5SJwwov6PjaADT-FqSO9ZgJEg6uUVXuPa03jmqyRB20HmsTvuDabVoK7Ky7Uug7V8J9yK4oOOK5d0aRRdgHXzxZd2yO8C4ggqsr1KQsfdlU4xRWglaZGI4S31ohCApJ0MUHaVnP5WkbC4FiTZAQ5fO_LcCokapzCLQyIuD5Ksdnj5Ad2ymiLQQ71TUNccN7BMX5aM4RHmztpEHOVbElCWXwyhWr3NR1Z1ar9s5ec6iHBqfkp_s8TvxPBLyUdy9OjCWy3iLQ4Lt4qpxsjwE4NE7KioDPX2Snb6NWFK7lvldjYX4tdkpWdQHBNmqaD8CuVCRdEQ\n",
      "[/code]\n",
      "Copy and save the `token` value. This will be used in your kubeconfig file.\n",
      "###### Get the certificate info for the cluster\n",
      "Every cluster has a certificate that clients can use to encrypt traffic. Fetch the certificate and write to a file (for example, `cluster-cert.txt)` by running this command:\n",
      "[code]\n",
      "    kubectl config view --flatten --minify > cluster-cert.txt\n",
      "    cat cluster-cert.txt\n",
      "[/code]\n",
      " **output**\n",
      "[code]\n",
      "    apiVersion: v1\n",
      "    clusters:\n",
      "    - cluster:\n",
      "        certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURDekNDQWZPZ0F3SUJBZ0lRZmo4VVMxNXpuaGRVbG15a3AvSVFqekFOQmdrcWhraUc5dzBCQVFzRkFEQXYKTVMwd0t3WURWUVFERXlSaVl6RTBOelV5WXkwMk9UTTFMVFExWldFdE9HTmlPUzFrWmpSak5tUXlZemd4TVRndwpIaGNOTVRnd05EQTVNVGd6TVRReVdoY05Nak13TkRBNE1Ua3pNVFF5V2pBdk1TMHdLd1lEVlFRREV5UmlZekUwCk56VXlZeTAyT1RNMUxUUTFaV0V0T0dOaU9TMWtaalJqTm1ReVl6Z3hNVGd3Z2dFaU1BMEdDU3FHU0liM0RRRUIKQVFVQUE0SUJEd0F3Z2dFS0FvSUJBUURIVHFPV0ZXL09odDFTbDBjeUZXOGl5WUZPZHFON1lrRVFHa3E3enkzMApPUEQydUZyNjRpRXRPOTdVR0Z0SVFyMkpxcGQ2UWdtQVNPMHlNUklkb3c4eUowTE5YcmljT2tvOUtMVy96UTdUClI0ZWp1VDl1cUNwUGR4b0Z1TnRtWGVuQ3g5dFdHNXdBV0JvU05reForTC9RN2ZpSUtWU01SSnhsQVJsWll4TFQKZ1hMamlHMnp3WGVFem5lL0tsdEl4NU5neGs3U1NUQkRvRzhYR1NVRzhpUWZDNGYzTk4zUEt3Wk92SEtRc0MyZAo0ajVyc3IwazNuT1lwWDFwWnBYUmp0cTBRZTF0RzNMVE9nVVlmZjJHQ1BNZ1htVndtejJzd2xPb24wcldlRERKCmpQNGVqdjNrbDRRMXA2WXJBYnQ1RXYzeFVMK1BTT2ROSlhadTFGWWREZHZyQWdNQkFBR2pJekFoTUE0R0ExVWQKRHdFQi93UUVBd0lDQkRBUEJnTlZIUk1CQWY4RUJUQURBUUgvTUEwR0NTcUdTSWIzRFFFQkN3VUFBNElCQVFCQwpHWWd0R043SHJpV2JLOUZtZFFGWFIxdjNLb0ZMd2o0NmxlTmtMVEphQ0ZUT3dzaVdJcXlIejUrZ2xIa0gwZ1B2ClBDMlF2RmtDMXhieThBUWtlQy9PM2xXOC9IRmpMQVZQS3BtNnFoQytwK0J5R0pFSlBVTzVPbDB0UkRDNjR2K0cKUXdMcTNNYnVPMDdmYVVLbzNMUWxFcXlWUFBiMWYzRUM3QytUamFlM0FZd2VDUDNOdHJMdVBZV2NtU2VSK3F4TQpoaVRTalNpVXdleEY4cVV2SmM3dS9UWTFVVDNUd0hRR1dIQ0J2YktDWHZvaU9VTjBKa0dHZXJ3VmJGd2tKOHdxCkdsZW40Q2RjOXJVU1J1dmlhVGVCaklIYUZZdmIxejMyVWJDVjRTWUowa3dpbHE5RGJxNmNDUEI3NjlwY0o1KzkKb2cxbHVYYXZzQnYySWdNa1EwL24KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\n",
      "        server: https://35.203.181.169\n",
      "      name: gke_jfrog-200320_us-west1-a_cluster\n",
      "    contexts:\n",
      "    - context:\n",
      "        cluster: gke_jfrog-200320_us-west1-a_cluster\n",
      "        user: gke_jfrog-200320_us-west1-a_cluster\n",
      "      name: gke_jfrog-200320_us-west1-a_cluster\n",
      "    current-context: gke_jfrog-200320_us-west1-a_cluster\n",
      "    kind: Config\n",
      "    preferences: {}\n",
      "    users:\n",
      "    - name: gke_jfrog-200320_us-west1-a_cluster\n",
      "      user:\n",
      "        auth-provider:\n",
      "          config:\n",
      "            access-token: ya29.Gl2YBba5duRR8Zb6DekAdjPtPGepx9Em3gX1LAhJuYzq1G4XpYwXTS_wF4cieZ8qztMhB35lFJC-DJR6xcB02oXXkiZvWk5hH4YAw1FPrfsZWG57x43xCrl6cvHAp40\n",
      "            cmd-args: config config-helper --format=json\n",
      "            cmd-path: /Users/ambarish/google-cloud-sdk/bin/gcloud\n",
      "            expiry: 2018-04-09T20:35:02Z\n",
      "            expiry-key: '{.credential.token_expiry}'\n",
      "            token-key: '{.credential.access_token}'\n",
      "          name: gcp\n",
      "[/code]\n",
      "Copy and save two pieces of information from here:\n",
      "  * `certificate-authority-data`\n",
      "  * `server`\n",
      "\n",
      "\n",
      "##### Configuring Permissions in Kubernetes\n",
      "Kubernetes includes a number of resources, including roles and role bindings that can be used to break your cluster into namespaces and limiting access to namespaced resources to specific accounts.\n",
      "This section provides information about defining permissions in Kubernetes using roles and role binding.\n",
      "###### Creating a Role\n",
      "A Role sets permissions within a particular namespace, which must be specified when creating a Role. Each Role has a `rules` section to define the resources that the rules apply to and the allowed operations, which are required for service account users to run builds within Kubernetes.\n",
      "For example, the following example creates a Role in the `jfrog` namespace, which will allow read/write access to all resources in the namespace:\n",
      "[code]\n",
      "    apiVersion: rbac.authorization.k8s.io/v1\n",
      "    kind: Role\n",
      "    metadata:\n",
      "      namespace: jfrog\n",
      "      name: pipelines-builder-role\n",
      "    rules:\n",
      "    - apiGroups: [\"\",\"apps\"]\n",
      "      resources: [\"persistentvolumeclaims\",\"secrets\",\"pods\",\"secrets\",\"configmaps\", \"deployments\", \"deployments/scale\", \"services\"]\n",
      "      verbs:\n",
      "      - get\n",
      "      - list\n",
      "      - watch\n",
      "      - create\n",
      "      - update\n",
      "      - patch\n",
      "      - delete\n",
      "[/code]\n",
      "###### Creating a Role Binding\n",
      "The service account that was created in the previous section can now be given the Role that was created earlier using a RoleBinding in the `jfrog` namespace:\n",
      "[code]\n",
      "    apiVersion: rbac.authorization.k8s.io/v1\n",
      "    kind: RoleBinding\n",
      "    metadata:\n",
      "      name: jfrog-builder-rb\n",
      "      namespace: jfrog\n",
      "    roleRef:\n",
      "      apiGroup: rbac.authorization.k8s.io\n",
      "      kind: Role\n",
      "      name: pipelines-builder-role\n",
      "    subjects:\n",
      "      - kind: ServiceAccount\n",
      "        name: pipelines-k8s-pool\n",
      "        namespace: jfrog\n",
      "[/code]\n",
      "##### Add a Kubernetes Administration Integration\n",
      "You must add a Kubernetes integration as an administration integration:\n",
      "  * From the JFrog Platform **Administration** module go to **Pipelines | Integrations**.\n",
      "  * Click **Add an Integration**.\n",
      "  * In the resulting **Add New Integration** display, click the _Integration Type_ field and select Kubernetes from the dropdown list.\n",
      "  * Enter a _Name_ for the Kubernetes integration\n",
      "  * Paste in a kubeconfig specification as described below\n",
      "  * Click **Create** to finish adding the Kubernetes integration\n",
      "\n",
      "\n",
      "###### Specify a kubeconfig\n",
      "From the steps in the prior sections, you should have the following pieces of information:\n",
      "  * <token>\n",
      "  * <certificate-authority-data>\n",
      "  * <server>\n",
      "\n",
      "\n",
      "The kubeconfig specification you paste into the _Kube Config_ setting should follow this format:\n",
      "[code]\n",
      "    apiVersion: v1\n",
      "    kind: Config\n",
      "    users:\n",
      "    - name: pipelines-k8s-pool                                               # <-- Your service account name\n",
      "      user:\n",
      "        token: <token>\n",
      "    clusters:\n",
      "    - cluster:\n",
      "        certificate-authority-data: <certificate-authority-data>\n",
      "        server: <server>\n",
      "      name: self-hosted-cluster\n",
      "    contexts:\n",
      "    - context:\n",
      "        cluster: self-hosted-cluster\n",
      "        user: pipelines-k8s-pool                                             # <-- Your service account name\n",
      "        namespace: jfrog                                                     # <-- The namespace you defined\n",
      "      name: pipelines_k8s_context\n",
      "    current-context: pipelines_k8s_context\n",
      "[/code]\n",
      "##### Create a Dynamic Node Pool\n",
      "Once you have successfully added the Kubernetes administration integration, you can add a dynamic node pool that uses it.\n",
      "Back to home page\n",
      "\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Experimenting data extartcion  \n",
    "'''\n",
    "import html2text\n",
    "url = 'https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-dynamic-nodes-on-kubernetes'\n",
    "# test = soup(responce.text, 'html.parser')\n",
    "def htmlTotext(url:str) -> str:\n",
    "    \n",
    "    responce = requests.get(url)\n",
    "    h = html2text.HTML2Text()\n",
    "    h.body_width = 0\n",
    "    h.ignore_links = True # to ignore the links \n",
    "    h.ignore_images = True # to ignore the images \n",
    "    h.ignore_tables = True  # To remove table tags and ignore the table \n",
    "    # h.ignore_emphasis =True\n",
    "    h.mark_code = True # to mark if code snipets are present its importent to identify yaml schma\n",
    "    h.single_line_break = True\n",
    "    return str(h.handle(responce.text))\n",
    "\n",
    "print(htmlTotext(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks:\n",
    " - From above obervations we have removed many unwanted lines and data by using various `html2text` options\n",
    " - We can also see output format is `markdown` its usefull when we show the output in GenAi as markdown\n",
    " - We also added `code block` in output which will useful when we print and extarct from bot output\n",
    " - Still we need to remove some data like sidebar data and some common unwanted lines(`back to homepage, ## JFrog Pipelines Documentation etc`) from data\n",
    " - `From various links  have verified first 250 lines and last line are same in all the docuemnt hence we can stripe them`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = htmlTotext(url)\n",
    "data = ('\\n').join(data.split('\\n')[250:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This tutorial explains how to specify a kubeconfig for a Kubernetes Integration to authenticate to a self-hosted Kubernetes cluster for a dynamic node pool. You can use a cloud provider solution like EKS, GKE, or AKS, or a self-hosted Kubernetes solution.\n",
      "This tutorial assumes that you have working knowledge of Docker and Kubernetes and understand the following concepts:\n",
      "  * Self hosting on GCP\n",
      "  * Self hosting on AWS\n",
      "  * kubeconfig files\n",
      "  * Configuring Service Accounts\n",
      "\n",
      "\n",
      "##### Configure a Kubernetes Service Account\n",
      "You must  configure a service account in Kubernetes to provide an identity for the build node processes that Pipelines will dynamically control.\n",
      "This procedure will use your personal account to create the service account. Make sure your personal account has permissions to do this.\n",
      "###### Verify Access to the Cluster\n",
      "First, make sure you can authenticate yourself to the cluster. This means you have a kubeconfig file that uses your personal account. You can verify this by running this command on your local machine and you should see the file listed.\n",
      "[code]\n",
      "    ls -al $HOME/.kube\n",
      "[/code]\n",
      " **Author a service account spec**\n",
      "To create a service account on Kubernetes, you can leverage `kubectl` and a service account spec. Create a YML file similar to the one below:\n",
      " **pipelines_k8s_sa.yml**\n",
      "[code]\n",
      "    apiVersion: v1\n",
      "    kind: ServiceAccount\n",
      "    metadata:\n",
      "      name: pipelines-k8s-pool   # <-- any name you'd like\n",
      "      namespace: jfrog           # <-- the cluster namespace\n",
      "[/code]\n",
      "###### Create the service account\n",
      "You can create a service account by running the following command:\n",
      "[code]\n",
      "    kubectl apply -f pipelines_k8s_sa.yaml\n",
      "[/code]\n",
      "##### Manually Create a Long-lived API Token for a ServiceAccount\n",
      "### Note\n",
      "Perform these steps if you are using Kubernetes 1.22 or higher, as these versions do not automatically create long-lived tokens. Versions of Kubernetes before v1.22 automatically created long term credentials for accessing the Kubernetes API.\n",
      "If you want to obtain an API token for a ServiceAccount, you create a new Secret with a special annotation, `kubernetes.io/service-account.name`.\n",
      "[code]\n",
      "    kubectl apply -f - <<EOF\n",
      "    apiVersion: v1\n",
      "    kind: Secret\n",
      "    metadata:\n",
      "      name: pipelines-k8s-pool\n",
      "      annotations:\n",
      "        kubernetes.io/service-account.name: pipelines-k8s-pool\n",
      "    type: kubernetes.io/service-account-token\n",
      "    EOF\n",
      "[/code]\n",
      "If you view the Secret using:\n",
      "`kubectl get secret/pipelines-k8s-pool -o yaml`\n",
      "you can see that the Secret now contains an API token for the \"`pipelines-k8s-pool`\" ServiceAccount.\n",
      "Because of the annotation you set, the control plane automatically generates a token for that ServiceAccounts, and stores them into the associated Secret. The control plane also cleans up tokens for deleted ServiceAccounts.\n",
      "`kubectl describe secrets/pipelines-k8s-pool`\n",
      "The output is similar to this:\n",
      "[code]\n",
      "    Name:           pipelines-k8s-pool\n",
      "    Namespace:      default\n",
      "    Labels:         <none>\n",
      "    Annotations:    kubernetes.io/service-account.name: pipelines-k8s-pool\n",
      "                    kubernetes.io/service-account.uid: da68f9c6-9d26-11e7-b84e-002dc52800da\n",
      "    \n",
      "    Type:   kubernetes.io/service-account-token\n",
      "    \n",
      "    Data\n",
      "    ====\n",
      "    ca.crt:         1338 bytes\n",
      "    namespace:      7 bytes\n",
      "    token:          ...\n",
      "[/code]\n",
      "When you delete a ServiceAccount that has an associated Secret, the Kubernetes control plane automatically cleans up the long-lived token from that Secret.\n",
      "##### Get Tokens and IP from Kubernetes\n",
      "Once the service account has been created, you will need to retrieve some key information from Kubernetes in order to configure it through a kubeconfig.\n",
      "###### Fetch the name of the secrets used by the service account\n",
      "This can be found by running the following command:\n",
      "[code]\n",
      "    kubectl describe serviceAccounts pipelines-k8s-pool\n",
      "[/code]\n",
      " **output**\n",
      "[code]\n",
      "    Name:               pipelines-k8s-pool\n",
      "    Namespace:          jfrog\n",
      "    Labels:             <none>\n",
      "    Annotations:        <none>\n",
      "    \n",
      "    Image pull secrets: <none>\n",
      "    Mountable secrets:  pipelines-k8s-pool-token-h6pdj\n",
      "    Tokens:             pipelines-k8s-pool-token-h6pdj\n",
      "[/code]\n",
      "Note the `Mountable secrets` string. This is the name of the secret that holds the token, and will be used in the next step. Or if you are on a later version of k8s, describe the secret you created in the last step.\n",
      "###### Fetch the token from the secret\n",
      "Using the `Mountable secrets` string, you can get the token used by the service account. Run the following command to extract this information:\n",
      "[code]\n",
      "    kubectl describe secrets pipelines-k8s-pool-token-h6pdj\n",
      "[/code]\n",
      " **output**\n",
      "[code]\n",
      "    Name:           pipelines-k8s-pool\n",
      "    Namespace:      jfrog\n",
      "    Labels:         <none>\n",
      "    Annotations:    kubernetes.io/service-account.name=pipelines-k8s-pool\n",
      "            kubernetes.io/service-account.uid=c2117d8e-3c2d-11e8-9ccd-42010a8a012f\n",
      "    \n",
      "    Type:   kubernetes.io/service-account-token\n",
      "    \n",
      "    Data\n",
      "    ====\n",
      "    ca.crt:     1115 bytes\n",
      "    namespace:  7 bytes\n",
      "    token:      eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJkZWZhdWx0Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZWNyZXQubmFtZSI6InNoaXBwYWJsZS1kZXBsb3ktdG9rZW4tN3Nwc2oiLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoic2hpcHBhYmxlLWRlcGxveSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImMyMTE3ZDhlLTNjMmQtMTFlOC05Y2NkLTQyMDEwYThhMDEyZiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDpkZWZhdWx0OnNoaXBwYWJsZS1kZXBsb3kifQ.ZWKrKdpK7aukTRKnB5SJwwov6PjaADT-FqSO9ZgJEg6uUVXuPa03jmqyRB20HmsTvuDabVoK7Ky7Uug7V8J9yK4oOOK5d0aRRdgHXzxZd2yO8C4ggqsr1KQsfdlU4xRWglaZGI4S31ohCApJ0MUHaVnP5WkbC4FiTZAQ5fO_LcCokapzCLQyIuD5Ksdnj5Ad2ymiLQQ71TUNccN7BMX5aM4RHmztpEHOVbElCWXwyhWr3NR1Z1ar9s5ec6iHBqfkp_s8TvxPBLyUdy9OjCWy3iLQ4Lt4qpxsjwE4NE7KioDPX2Snb6NWFK7lvldjYX4tdkpWdQHBNmqaD8CuVCRdEQ\n",
      "[/code]\n",
      "Copy and save the `token` value. This will be used in your kubeconfig file.\n",
      "###### Get the certificate info for the cluster\n",
      "Every cluster has a certificate that clients can use to encrypt traffic. Fetch the certificate and write to a file (for example, `cluster-cert.txt)` by running this command:\n",
      "[code]\n",
      "    kubectl config view --flatten --minify > cluster-cert.txt\n",
      "    cat cluster-cert.txt\n",
      "[/code]\n",
      " **output**\n",
      "[code]\n",
      "    apiVersion: v1\n",
      "    clusters:\n",
      "    - cluster:\n",
      "        certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURDekNDQWZPZ0F3SUJBZ0lRZmo4VVMxNXpuaGRVbG15a3AvSVFqekFOQmdrcWhraUc5dzBCQVFzRkFEQXYKTVMwd0t3WURWUVFERXlSaVl6RTBOelV5WXkwMk9UTTFMVFExWldFdE9HTmlPUzFrWmpSak5tUXlZemd4TVRndwpIaGNOTVRnd05EQTVNVGd6TVRReVdoY05Nak13TkRBNE1Ua3pNVFF5V2pBdk1TMHdLd1lEVlFRREV5UmlZekUwCk56VXlZeTAyT1RNMUxUUTFaV0V0T0dOaU9TMWtaalJqTm1ReVl6Z3hNVGd3Z2dFaU1BMEdDU3FHU0liM0RRRUIKQVFVQUE0SUJEd0F3Z2dFS0FvSUJBUURIVHFPV0ZXL09odDFTbDBjeUZXOGl5WUZPZHFON1lrRVFHa3E3enkzMApPUEQydUZyNjRpRXRPOTdVR0Z0SVFyMkpxcGQ2UWdtQVNPMHlNUklkb3c4eUowTE5YcmljT2tvOUtMVy96UTdUClI0ZWp1VDl1cUNwUGR4b0Z1TnRtWGVuQ3g5dFdHNXdBV0JvU05reForTC9RN2ZpSUtWU01SSnhsQVJsWll4TFQKZ1hMamlHMnp3WGVFem5lL0tsdEl4NU5neGs3U1NUQkRvRzhYR1NVRzhpUWZDNGYzTk4zUEt3Wk92SEtRc0MyZAo0ajVyc3IwazNuT1lwWDFwWnBYUmp0cTBRZTF0RzNMVE9nVVlmZjJHQ1BNZ1htVndtejJzd2xPb24wcldlRERKCmpQNGVqdjNrbDRRMXA2WXJBYnQ1RXYzeFVMK1BTT2ROSlhadTFGWWREZHZyQWdNQkFBR2pJekFoTUE0R0ExVWQKRHdFQi93UUVBd0lDQkRBUEJnTlZIUk1CQWY4RUJUQURBUUgvTUEwR0NTcUdTSWIzRFFFQkN3VUFBNElCQVFCQwpHWWd0R043SHJpV2JLOUZtZFFGWFIxdjNLb0ZMd2o0NmxlTmtMVEphQ0ZUT3dzaVdJcXlIejUrZ2xIa0gwZ1B2ClBDMlF2RmtDMXhieThBUWtlQy9PM2xXOC9IRmpMQVZQS3BtNnFoQytwK0J5R0pFSlBVTzVPbDB0UkRDNjR2K0cKUXdMcTNNYnVPMDdmYVVLbzNMUWxFcXlWUFBiMWYzRUM3QytUamFlM0FZd2VDUDNOdHJMdVBZV2NtU2VSK3F4TQpoaVRTalNpVXdleEY4cVV2SmM3dS9UWTFVVDNUd0hRR1dIQ0J2YktDWHZvaU9VTjBKa0dHZXJ3VmJGd2tKOHdxCkdsZW40Q2RjOXJVU1J1dmlhVGVCaklIYUZZdmIxejMyVWJDVjRTWUowa3dpbHE5RGJxNmNDUEI3NjlwY0o1KzkKb2cxbHVYYXZzQnYySWdNa1EwL24KLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\n",
      "        server: https://35.203.181.169\n",
      "      name: gke_jfrog-200320_us-west1-a_cluster\n",
      "    contexts:\n",
      "    - context:\n",
      "        cluster: gke_jfrog-200320_us-west1-a_cluster\n",
      "        user: gke_jfrog-200320_us-west1-a_cluster\n",
      "      name: gke_jfrog-200320_us-west1-a_cluster\n",
      "    current-context: gke_jfrog-200320_us-west1-a_cluster\n",
      "    kind: Config\n",
      "    preferences: {}\n",
      "    users:\n",
      "    - name: gke_jfrog-200320_us-west1-a_cluster\n",
      "      user:\n",
      "        auth-provider:\n",
      "          config:\n",
      "            access-token: ya29.Gl2YBba5duRR8Zb6DekAdjPtPGepx9Em3gX1LAhJuYzq1G4XpYwXTS_wF4cieZ8qztMhB35lFJC-DJR6xcB02oXXkiZvWk5hH4YAw1FPrfsZWG57x43xCrl6cvHAp40\n",
      "            cmd-args: config config-helper --format=json\n",
      "            cmd-path: /Users/ambarish/google-cloud-sdk/bin/gcloud\n",
      "            expiry: 2018-04-09T20:35:02Z\n",
      "            expiry-key: '{.credential.token_expiry}'\n",
      "            token-key: '{.credential.access_token}'\n",
      "          name: gcp\n",
      "[/code]\n",
      "Copy and save two pieces of information from here:\n",
      "  * `certificate-authority-data`\n",
      "  * `server`\n",
      "\n",
      "\n",
      "##### Configuring Permissions in Kubernetes\n",
      "Kubernetes includes a number of resources, including roles and role bindings that can be used to break your cluster into namespaces and limiting access to namespaced resources to specific accounts.\n",
      "This section provides information about defining permissions in Kubernetes using roles and role binding.\n",
      "###### Creating a Role\n",
      "A Role sets permissions within a particular namespace, which must be specified when creating a Role. Each Role has a `rules` section to define the resources that the rules apply to and the allowed operations, which are required for service account users to run builds within Kubernetes.\n",
      "For example, the following example creates a Role in the `jfrog` namespace, which will allow read/write access to all resources in the namespace:\n",
      "[code]\n",
      "    apiVersion: rbac.authorization.k8s.io/v1\n",
      "    kind: Role\n",
      "    metadata:\n",
      "      namespace: jfrog\n",
      "      name: pipelines-builder-role\n",
      "    rules:\n",
      "    - apiGroups: [\"\",\"apps\"]\n",
      "      resources: [\"persistentvolumeclaims\",\"secrets\",\"pods\",\"secrets\",\"configmaps\", \"deployments\", \"deployments/scale\", \"services\"]\n",
      "      verbs:\n",
      "      - get\n",
      "      - list\n",
      "      - watch\n",
      "      - create\n",
      "      - update\n",
      "      - patch\n",
      "      - delete\n",
      "[/code]\n",
      "###### Creating a Role Binding\n",
      "The service account that was created in the previous section can now be given the Role that was created earlier using a RoleBinding in the `jfrog` namespace:\n",
      "[code]\n",
      "    apiVersion: rbac.authorization.k8s.io/v1\n",
      "    kind: RoleBinding\n",
      "    metadata:\n",
      "      name: jfrog-builder-rb\n",
      "      namespace: jfrog\n",
      "    roleRef:\n",
      "      apiGroup: rbac.authorization.k8s.io\n",
      "      kind: Role\n",
      "      name: pipelines-builder-role\n",
      "    subjects:\n",
      "      - kind: ServiceAccount\n",
      "        name: pipelines-k8s-pool\n",
      "        namespace: jfrog\n",
      "[/code]\n",
      "##### Add a Kubernetes Administration Integration\n",
      "You must add a Kubernetes integration as an administration integration:\n",
      "  * From the JFrog Platform **Administration** module go to **Pipelines | Integrations**.\n",
      "  * Click **Add an Integration**.\n",
      "  * In the resulting **Add New Integration** display, click the _Integration Type_ field and select Kubernetes from the dropdown list.\n",
      "  * Enter a _Name_ for the Kubernetes integration\n",
      "  * Paste in a kubeconfig specification as described below\n",
      "  * Click **Create** to finish adding the Kubernetes integration\n",
      "\n",
      "\n",
      "###### Specify a kubeconfig\n",
      "From the steps in the prior sections, you should have the following pieces of information:\n",
      "  * <token>\n",
      "  * <certificate-authority-data>\n",
      "  * <server>\n",
      "\n",
      "\n",
      "The kubeconfig specification you paste into the _Kube Config_ setting should follow this format:\n",
      "[code]\n",
      "    apiVersion: v1\n",
      "    kind: Config\n",
      "    users:\n",
      "    - name: pipelines-k8s-pool                                               # <-- Your service account name\n",
      "      user:\n",
      "        token: <token>\n",
      "    clusters:\n",
      "    - cluster:\n",
      "        certificate-authority-data: <certificate-authority-data>\n",
      "        server: <server>\n",
      "      name: self-hosted-cluster\n",
      "    contexts:\n",
      "    - context:\n",
      "        cluster: self-hosted-cluster\n",
      "        user: pipelines-k8s-pool                                             # <-- Your service account name\n",
      "        namespace: jfrog                                                     # <-- The namespace you defined\n",
      "      name: pipelines_k8s_context\n",
      "    current-context: pipelines_k8s_context\n",
      "[/code]\n",
      "##### Create a Dynamic Node Pool\n",
      "Once you have successfully added the Kubernetes administration integration, you can add a dynamic node pool that uses it.\n",
      "\n",
      " Document url for reference - https://jfrog.com/help/r/jfrog-pipelines-documentation/creating-dynamic-nodes-on-kubernetes\n"
     ]
    }
   ],
   "source": [
    "data = data + f'\\n\\n Document url for reference - {url}'  # we can append this for reference link in answer\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarks:\n",
    "`Able to successully extract the data for our desired format now we can append the data from each link and prepare the data for training`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "final Function to concat all the data\n",
    "'''\n",
    "import pandas as pd # for dataframe creation and convert to csv\n",
    "from tqdm import tqdm\n",
    "pd.set_option('display.max_colwidth',None)\n",
    "\n",
    "def dataOrchestrator(url:str) -> pd.DataFrame:\n",
    "    ''' \n",
    "    This function will take the parent portal URL and extrcat links and data from all pipline procedures\n",
    "    and return pandas DataFareme \n",
    "    '''\n",
    "    dataFrame = pd.DataFrame(columns=['Title', 'PiplineProcess'])\n",
    "    all_links = tqdm(linkExtarction(url), desc=f'Extrating all the links from - {url}')\n",
    "    pipline_links = tqdm(filter_links(all_links), desc=f'Filtering only pipline links')\n",
    "    for link in tqdm(pipline_links, desc=f'Data extraction in progress...'):\n",
    "        temp_data = htmlTotext(link)\n",
    "        data = ('\\n').join(temp_data.split('\\n')[250:-2]) # striping first 250 and last line\n",
    "        data = data + f'\\n\\n Document url for reference - {url}' # Adding refernce URL at the end of every answer\n",
    "        templist = [[link[55:], data]]\n",
    "        dataFrame = dataFrame._append(pd.DataFrame(templist, columns=['Title', 'PiplineProcess']),ignore_index=True)\n",
    "    return dataFrame\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extrating all the links from - https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps: 100%|| 329/329 [00:00<00:00, 249264.09it/s]\n",
      "Filtering only pipline links: 100%|| 244/244 [04:33<00:00,  1.12s/it]\n",
      "Data extraction in progress...: 100%|| 244/244 [04:33<00:00,  1.12s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>PiplineProcess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jfrog-pipelines</td>\n",
       "      <td>JFrog Pipelines offers JFrog Platform customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pipelines-use-cases</td>\n",
       "      <td>Let's explore some of the most common ways to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pipelines-concepts</td>\n",
       "      <td>Before learning how to use Pipelines, here are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pipelines-step-by-step</td>\n",
       "      <td>After you have a Pipelines installation workin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>see-it-live</td>\n",
       "      <td>Have we piqued your interest? Ready to see som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>managing-runtimes</td>\n",
       "      <td>Every step in your pipeline executes on a buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>choosing-your-runtime-image</td>\n",
       "      <td>By default, your steps run inside a container ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>running-steps-on-the-host</td>\n",
       "      <td>When you need to execute your step directly on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>choosing-node-pools</td>\n",
       "      <td>A pipeline can, if necessary, control through ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>runtime-images</td>\n",
       "      <td>A runtime image is the Docker image for the co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Title  \\\n",
       "0                jfrog-pipelines   \n",
       "1            pipelines-use-cases   \n",
       "2             pipelines-concepts   \n",
       "3         pipelines-step-by-step   \n",
       "4                    see-it-live   \n",
       "..                           ...   \n",
       "239            managing-runtimes   \n",
       "240  choosing-your-runtime-image   \n",
       "241    running-steps-on-the-host   \n",
       "242          choosing-node-pools   \n",
       "243               runtime-images   \n",
       "\n",
       "                                        PiplineProcess  \n",
       "0    JFrog Pipelines offers JFrog Platform customer...  \n",
       "1    Let's explore some of the most common ways to ...  \n",
       "2    Before learning how to use Pipelines, here are...  \n",
       "3    After you have a Pipelines installation workin...  \n",
       "4    Have we piqued your interest? Ready to see som...  \n",
       "..                                                 ...  \n",
       "239  Every step in your pipeline executes on a buil...  \n",
       "240  By default, your steps run inside a container ...  \n",
       "241  When you need to execute your step directly on...  \n",
       "242  A pipeline can, if necessary, control through ...  \n",
       "243  A runtime image is the Docker image for the co...  \n",
       "\n",
       "[244 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finale data extraction\n",
    "parentUrl = 'https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps'\n",
    "final_data = dataOrchestrator(parentUrl)\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>PiplineProcess</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jfrog-pipelines</td>\n",
       "      <td>JFrog Pipelines offers JFrog Platform customers three vital capabilities: end-to-end automation (CI/CD), workflow and tool orchestration, and the optimization of the JFrog toolset functionality in use. Consistent with JFrogs customer-centric product philosophy, Pipelines is enterprise-ready and universal.\\n### Workflow Automation\\nA pipeline is an event-driven automated workflow for executing a set of DevOps activities (CI, deployments, infrastructure provisioning, etc). It is composed of a sequence of interdependent **steps** which execute discrete functions. Steps act on **resources** , which hold the information needed to execute (files, key-value pairs, etc).\\nDevelopers can create pipelines easily with a simple declarative YAML-based language. While each step in a pipeline executes in a stateless runtime environment, Pipelines provides facilities to manage state and step outputs across the workflow so that all dependent steps can access the information they need from upstream steps in order to execute. This helps coordinate activities centrally across diverse DevOps tools and teams without custom DIY scripts.\\nWorkflows can be configured for a variety of scenarios, including:\\n  * Continuous Integration for your applications\\n  * Continuous Delivery workflows that connect all your CI/CD and DevOps activities across tools and functional silos\\n  * Automate IT Ops workflows like infrastructure provisioning, security patching, and image building\\n\\n\\n### Get up and running with JFrog Pipelines\\nIn this section, you will find information to get you started whether you are a new user or an existing user.\\n  * If you do not yet have a subscription, get started with trial subscription of the JFrog Platform on the Cloud.\\n  * If you are a new user, get started with the onboarding videos for JFrog Pipelines.Onboarding Best Practices: JFrog Pipelines\\n\\n\\n### Features\\n#### Pipelines as Code\\nDefine your automated workflow through code, using a domain specific language in a YAML file of key-value pairs that you can create and maintain with your favorite text editor.\\n#### Real Time Visibility\\nJFrog Pipelines renders your pipeline definition as an interactive diagram, helping you to see the flow of tasks and their inter-dependencies, as well as view the success record of any runs that were performed.\\n#### Universal\\nConnect your pipeline automation to your source code repositories in a version control system (such as GitHub or BitBucket) to automatically trigger execution on any new submission (commit) of a code change. Connect to other popular tools through your credentials for storage, issue-tracking, notification, orchestration and more through a library of integrations.\\n#### Native Integration with Artifactory\\nJFrog Pipelines is designed to be used with Artifactory, with built-in directives for pushing artifacts, performing builds, pushing build information, image scanning, and build promotion.\\n#### Integration with JFrog Platform\\nJFrog Pipelines is designed as an integral part of the JFrog platform, including scanning artifacts/builds through Xray, the creation and delivery of release bundles through JFrog Distribution, for a complete end-to-end SDLC pipeline from commit to production runtime.\\n#### Security First\\nFine-grained permissions and access control limit who can access workflows. Centralized, encrypted storage of credentials and keys help ensure secrets stay safe.\\n#### Enterprise-Ready\\nManage multiple execution nodes using a single installation of Pipelines and automatically distribute Pipeline execution across them for scale and speed.\\n### Watch the Screencast\\n\\n Document url for reference - https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>dockerbuild</td>\n",
       "      <td>The **DockerBuild** native step performs a build to produce a Docker image from a Dockerfile in a GitRepo source repository resource.\\nIn the step configuration, you must provide the name ( `dockerFileName` ) and directory ( `dockerFileLocation` ) of the Dockerfile that contains the command to be processed by a `docker build` command, as well as the name ( `dockerImageName` ) and tag ( `dockerImageTag` ) of the resulting image. The image is built on the build node, and information about that image is stored in the run state.\\nTo build a Docker image that relies on a private base image:\\n  1. Define the base image as an Image resource, with `autoPull` set to `true`.\\n  2. Specify the Image resource as one of the `inputResources` of the DockerBuild step.\\n\\n\\nTo include artifacts in the Docker image that are not part of the GitRepo source repository:\\n  1. Define a FileSpec resource that specifies the files to include from Artifactory.\\n  2. Specify the FileSpec resource as one of the `inputResources`of the DockerBuild step.\\n\\n\\n### Proper usage of DockerBuild step\\nDockerBuild and DockerPush steps must be assigned to the same `affinityGroup` to share state. If this is not done, the output of DockerBuild will not be available for DockerPush. For more information on using `affinityGroup`, see Running multiple steps on the same build node.\\n### Docker Build and Push Quickstart\\nThis Docker Build and Push quickstart demonstrates the definition of a pipeline that uses the DockerBuild and DockerPush native steps to build a single Docker Image, push it to Artifactory, and then publish the BuildInfo.\\n##### YAML Schema\\nThe YAML schema for DockerBuild native step is as follows:\\n **DockerBuild**\\n[code]\\n    pipelines: \\n      - name: &lt;string&gt;\\n        steps:\\n          - name: &lt;string&gt;\\n            type: DockerBuild\\n            configuration:\\n              #inherits all the tags from bash\\n              affinityGroup:       &lt;string&gt;\\n              dockerFileLocation:  &lt;string&gt;\\n              dockerFileName:      &lt;string&gt;\\n              dockerImageName:     &lt;string&gt;\\n              dockerImageTag:      &lt;string&gt;\\n              dockerOptions:       &lt;string&gt;\\n    \\n              integrations:\\n                - name:            &lt;artifactory or docker registry integration&gt;  # required\\n    \\n              inputResources:\\n                - name:             &lt;GitRepo resource&gt;        # required, git repository containing your Dockerfile\\n                - name:             &lt;Image resource&gt;          # optional base image\\n                - name:             &lt;FileSpec resource&gt;       # optional\\n    \\n            execution:\\n              onStart:\\n                - echo \"Preparing for work...\"\\n              onSuccess:\\n                - echo \"Job well done!\"\\n              onFailure:\\n                - echo \"uh oh, something went wrong\"\\n              onComplete: #always\\n                - echo \"Cleaning up some stuff\"\\n[/code]\\n##### Tags\\n###### name\\nAn alphanumeric string (underscores are permitted) that identifies the step.\\n###### type\\nMust be `DockerBuild` for this step type.\\n###### configuration\\nSpecifies all configuration selections for the step's execution environment. This step inherits the Bash/ PowerShell step configuration tags, including these pertinenttags:\\nTag\\n **Description of usage**\\nRequired/Optional  \\n`affinityGroup`\\nMust specify an affinity group string that is the same as specified in a subsequent DockerPush step.\\nOptional  \\n`inputResources`\\nMust specify:\\n  * a GitRepo resource (that contains the Dockerfile)\\n\\n\\nOptionally, you may also specify:\\n  * One or more Image resources to pull base images used in the build or to trigger this build.\\n  * One or more FileSpec resources that specify what files to include in the build context. These files are automatically copied to `dockerFileLocation`.\\n\\n\\nRequired/Optional  \\nIn addition, these tags can be defined to support the step's native operation:\\n### Tags derived from Bash\\nAll native steps derive from the Bash step. This means that all steps share the same base set of tags from Bash, while native steps have their own additional tags as well that support the step's particular function. So it's important to be familiar with the Bash step definition, since it's the core of the definition of all other steps.\\nTag\\n **Description of usage**\\nRequired/Optional  \\n`dockerFileLocation`\\nDirectory containing the Dockerfile, which is the file that has Docker build configuration. This file is also used as the context for the Docker build. The path provided should be relative to the root of the input GitRepo repository. If no location is provided, the default is the root of the GitRepo repository.\\nRequired  \\n`dockerFileName`\\nName of the Dockerfile.\\nRequired  \\n`dockerImageName`\\nThe name of the Docker image to create. This can be set using environment variables or triggering a run using parameters.\\nRequired  \\n`dockerImageTag`\\nThe tag for the Docker image to create. This can be set using environment variables or triggering a run using parameters.\\nRequired  \\n`dockerOptions`\\nAdditional options for the docker build command.\\nOptional  \\n###### execution\\nDeclares collections of shell command sequences to perform for pre- and post-execution phases:\\nTag\\n **Description of usage**\\nRequired/Optional  \\n`onStart`\\nCommands to execute in advance of the native operation\\nOptional  \\n`onSuccess`\\nCommands to execute on successful completion\\nOptional  \\n`onFailure`\\nCommands to execute on failed completion\\nOptional  \\n`onComplete`\\nCommands to execute on any completion\\nOptional  \\nThe actions performed for the `onExecute` phase are inherent to this step type and may not be overridden.\\n##### Examples\\nThe following examples use a GoLang Git repository represented by a GitRepo resource named `gosvc_app` to create a Docker image that is published to Artifactory. They assume that an Artifactory integration named `MyArtifactory` has been created, and that the Artifactory instance has a Docker repository mapped to `docker.artprod.company`.\\n  * These examples require an Artifactory Integration and a GitHub Integration.GitHub Integration\\n  * The Pipelines DSL for a similar example is available in this repository in the JFrog GitHub account.\\n  * For a full tutorial, see Pipeline Example: Docker Build and Push.\\n\\n\\nThe following resources declarations support these examples. Not all of these resources are used in all examples.\\n###### Resources\\n[code]\\n    resources:\\n    # Application source repository\\n      - name: gosvc_app\\n        type: GitRepo\\n        configuration:\\n          gitProvider: myGithub\\n          path: myuser/myrepo                   # replace with your repository name\\n          branches:\\n            include: master\\n    \\n    # Docker image in an Artifactory repository\\n      - name: base_image\\n        type: Image\\n        configuration:\\n          registry: myArtifactory\\n          sourceRepository: docker-local        # replace with your repository name\\n          imageName: docker.artprod.mycompany.com/baseimage\\n          imageTag: latest\\n          autoPull: true\\n    \\n    # Files in an Artifactory repository\\n      - name: icon_files\\n        type: FileSpec\\n        configuration:\\n          sourceArtifactory: myArtifactory\\n          pattern: my-local-repo/all-my-images/\\n          target: icons/\\n[/code]\\n###### Build a Docker image from a source repository\\nThis example builds a Docker image to a Docker registry in Artifactory. The tag for the image is set to the pipeline's run number.\\n[code]\\n    pipelines:\\n      - name: demo_pipeline\\n        steps:\\n          - name: bld_image\\n            type: DockerBuild\\n            configuration:\\n              dockerFileLocation: .\\n              dockerFileName: Dockerfile\\n              dockerImageName: docker.artprod.mycompany.com/gosvc    # replace with your fully qualified Docker registry/image name\\n              dockerImageTag: ${run_number}\\n              inputResources:\\n                - name: gosvc_app\\n              integrations:\\n                - name: MyArtifactory\\n[/code]\\n###### Build a Docker image with dockerOptions\\nThis example demonstrates use of the `dockerOptions` tag to set the `build-arg` option for the Docker command. An environment variable named `build_number_env_variable` is dynamically set to the pipeline's run number. The example assumes the environment variable is used in the Dockerfile commands.\\n[code]\\n    pipelines:\\n      - name: demo_pipeline\\n        steps:\\n          - name: bld_image\\n            type: DockerBuild\\n            configuration:\\n              dockerFileLocation: .\\n              dockerFileName: Dockerfile\\n              dockerImageName: docker.artprod.mycompany.com/gosvc   # replace with your fully qualified Docker registry/image name\\n              dockerImageTag: ${run_number}\\n              dockerOptions: --build-arg build_number_env_variable=${run_number}           \\n              inputResources:\\n                - name: gosvc_app\\n              integrations:\\n                - name: MyArtifactory\\n[/code]\\n###### Build a Docker image with a private base image\\nThis example builds a Docker image that relies on a private base image stored in an Artifactory Docker repository.\\n[code]\\n    pipelines:\\n      - name: demo_pipeline\\n        steps:\\n          - name: bld_image\\n            type: DockerBuild\\n            configuration:\\n              dockerFileLocation: .\\n              dockerFileName: Dockerfile\\n              dockerImageName: docker.artprod.mycompany.com/gosvc       # replace with your fully qualified Docker registry/image name\\n              dockerImageTag: ${run_number}\\n              inputResources:\\n                - name: gosvc_app\\n                - name: base_image\\n              integrations:\\n                - name: MyArtifactory\\n[/code]\\n###### Build a Docker image with files outside the current path\\nThis example demonstrates building a Docker image that includes files outside of the current path. It pulls icon files stored in an Artifactory repository for integration art named `my-local-repo`. It is assumed that the Dockerfile has a command that will include the files in `/icons` into the image.\\n[code]\\n    pipelines:\\n      - name: demo_pipeline\\n        steps:\\n          - name: bld_image\\n            type: DockerBuild\\n            configuration:\\n              dockerFileLocation: .\\n              dockerFileName: Dockerfile\\n              dockerImageName: docker.artprod.mycompany.com/gosvc         # replace with your fully qualified Docker registry/image name\\n              dockerImageTag: ${run_number}\\n              inputResources:\\n                - name: gosvc_app\\n                - name: icon_files\\n              integrations:\\n                - name: MyArtifactory\\n[/code]\\n##### How it Works\\nWhen you use the **DockerBuild** native step in a pipeline, it performs the following functions in the background:\\n  * cp (if there is a FileSpec input, copy those files to the root of the cloned GitRepo input)\\n  * docker build\\n  * add_run_variables (add several variables that are later used when pushing the Docker image or publishing build info)\\n  * jfrog rt build-collect-env (collect environment information to be later published as part of build info)\\n  * add_run_files (save information collected for build info)\\n\\n\\n\\n Document url for reference - https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>uploadartifact</td>\n",
       "      <td>The **UploadArtifact** native step uploads artifacts to Artifactory. Optionally, it can also publish build information to Artifactory and trigger Xray scans.\\nThis step utilizes the JFrog CLI to upload an artifact to Artifactory. The file(s) may be provided in a FileSpec, if already in Artifactory, or RemoteFile or GitRepo input.\\n##### YAML Schema\\nThe YAML schema for UploadArtifact native step is as follows:\\n **UploadArtifact**\\n[code]\\n    pipelines: \\n      - name:   &lt;string&gt;\\n        steps:\\n          - name: &lt;string&gt;\\n            type: UploadArtifact\\n            configuration:\\n              targetPath:           &lt;string&gt;  #required\\n              sourcePath:           &lt;string&gt;  #optional\\n              properties:           &lt;string&gt;  #optional\\n                      regExp:                       &lt;boolean&gt; #optional\\n              flat:                 &lt;boolean&gt; #optional\\n                      module:                       &lt;string&gt;  #optional\\n                      deb:                  &lt;string&gt;  #optional\\n                      recursive:                &lt;boolean&gt;     #optional\\n                      dryRun:                       &lt;boolean&gt; #optional\\n              symlinks:                     &lt;boolean&gt; #optional\\n              explode:                      &lt;boolean&gt; #optional\\n              exclusions:               &lt;string&gt;      #optional\\n              includeDirs:              &lt;boolean&gt;     #optional\\n              syncDeletes:              &lt;string&gt;      #optional\\n              forceXrayScan:                &lt;boolean&gt; #optional\\n              failOnScan:           &lt;boolean&gt;   # default true\\n                      autoPublishBuildInfo: &lt;boolean&gt; #optional\\n              inputResources:\\n                            - name: myGitRepo       \\n                            - name: artifactoryFileSpec     \\n                - name: myRemoteFile        \\n                      outputResources:\\n                - name: myFileSpec\\n                            - name: myBuildInfo\\n              integrations:\\n                            - name: myArtifactory \\n            execution:\\n              onStart:\\n                - echo \"Preparing for work...\"\\n              onSuccess:\\n                - echo \"Job well done!\"\\n              onFailure:\\n                - echo \"uh oh, something went wrong\"\\n              onComplete: #always\\n                - echo \"Cleaning up some stuff\"\\n    \\n[/code]\\n##### Tags\\n###### name\\nAn alphanumeric string (underscores are permitted) that identifies the step.\\n###### type\\nMust be `UploadArtifact` for this step type.\\n###### configuration\\nSpecifies all configuration selections for the step's execution environment. This step inherits the Bash/ PowerShell step configuration tags, including these pertinent tags:\\nTag\\n **Description of usage**\\nRequired/Optional  \\n`integrations`\\nMust specify an  Artifactory Integration.\\nRequired  \\n`inputResources`\\nMay specify a GitRepo, FileSpec, or RemoteFile resource containing the file(s) to be uploaded. One of each type may be specified.\\nOptional  \\n`outputResources`\\nMust specify a BuildInfo resource if `autoPublishBuildInfo` is set as `true`.\\nIf `JFROG_CLI_BUILD_NAME` or `JFROG_CLI_BUILD_NUMBER` is set as an environment variable for the pipeline or the step, that name and/or number is used for the output BuildInfo. Otherwise, the default `buildName` and `buildNumber` are `$pipeline_name` and `$run_number.`\\nMay also specify a FileSpec resource to be updated with the pattern and properties of the uploaded Artifact.\\nMay be required  \\nIn addition, these tags can be defined to support the step's native operation:\\nTag\\n **Description of usage**\\nRequired/Optional  \\ntargetPath\\nPath to upload the files, including repository name.\\nRequired  \\n`sourcePath`\\nFiles to upload. If this is a relative path pattern, it is relative to the root of a GitRepo/FileSpec/RemoteFile input.\\nDefault is `*` when `regExp` is `false` and `.*` when `regExp` is `true`.\\nOptional  \\n`properties`\\nSemi-colon separated properties for the uploaded artifact. For example: `myFirstProperty=one;mySecondProperty=two`.\\nProperties `pipelines_step_name`, `pipelines_run_number`, `pipelines_step_id`, `pipelines_pipeline_name`, `pipelines_step_url`, `pipelines_step_type`, and `pipelines_step_platform` will also be added.\\nOptional  \\n`regExp`\\nWhen set as `true`, regular expressions are used in other parameters, such as `sourcePath`, instead of wildcards. Expressions must be in parentheses.\\nDefault is `false`.\\nOptional  \\n`flat`\\nWhen set as `true`, the uploaded files are flattened, removing the directory structure.\\nDefault is `false`.\\nOptional  \\n`module`\\nA module name for the Build Info.\\nOptional  \\n`deb`\\nA `distribution/component/architecture` for Debian packages. If the distribution, component, or architecture includes a / it must be double-escaped, For example: `distribution/my\\\\\\/component/architecture` for a `my/component` component.\\nOptional  \\n`recursive`\\nWhen set as `false`, do not upload any matches in subdirectories.\\nDefault is true.\\nOptional  \\n`dryRun`\\nWhen set as `true`, nothing is uploaded.\\nDefault is `false`.\\nOptional  \\n`symlinks`\\nWhen set as `true`, symlinks matching the other criteria are uploaded.\\nDefault is `false`.\\nOptional  \\n`explode`\\nWhen set as `true` and the uploaded Artifact is an archive, the archive is expanded.\\nDefault is `false`.\\nOptional  \\n`exclusions`\\nSemi-colon separated patterns to exclude.\\nOptional  \\n`includeDirs`\\nWhen set as `true`, empty directories matching the criteria are uploaded.\\nDefault is `false`.\\nOptional  \\n`syncDeletes`\\nA path under which to delete any existing files in Artifactory.\\nOptional  \\n`forceXrayScan`\\nWhen set as `true`, forces an Xray scan after publishing to Artifactory.\\nDefault is `false`.\\nOptional  \\n`failOnScan`\\nWhen set as `true`, and when the Xray Policy Rule  Fail Build checkbox is checked, a failed Xray scan will result in a failure of the step.Creating Xray Policies and Rules\\nDefault is `true`.\\nOptional  \\n`autoPublishBuildInfo`\\nWhen set as `true`, publishes build info to Artifactory.\\nDefault is `false`.\\nOptional  \\n###### execution\\nDeclares collections of shell command sequences to perform for pre- and post-execution phases:\\nTag\\n **Description of usage**\\nRequired/Optional  \\n`onStart`\\nCommands to execute in advance of the native operation\\nOptional  \\n`onSuccess`\\nCommands to execute on successful completion\\nOptional  \\n`onFailure`\\nCommands to execute on failed completion\\nOptional  \\n`onComplete`\\nCommands to execute on any completion\\nOptional  \\nThe actions performed for the `onExecute` phase are inherent to this step type and may not be overridden.\\n### Note\\n`onExecute`, `onStart`, `onSuccess`, `onFailure`, and `onComplete` are reserved keywords. Using these keywords in any other context in your execution scripts can cause unexpected behavior.\\n##### Examples\\nThe following examples show a few ways in which a UploadArtifact step can be configured.\\n###### Uploading an Artifact to Another Repository using a FileSpec Resource\\nThe most basic form of UploadArtifact. Uses all default values. This step will download the file matching the FileSpec and upload it to the location in `targetPath`. The optional output FileSpec resource will be updated with the `targetPath` and the default properties added to the uploaded artifact.\\n **UploadArtifact**\\n[code]\\n    pipelines: \\n      - name: uploadArtifactPipeline\\n        steps:\\n          - name: uploadArtifactStep\\n            type: UploadArtifact\\n            configuration:\\n              targetPath: my-repository/myDirectory/myFile.txt\\n              integrations:\\n                - name: myArtifactoryIntegration\\n              inputResources:\\n                - name: myInputFileSpec\\n              outputResources:\\n                - name: myOutputFileSpec\\n    \\n[/code]\\n###### Uploading an Artifact from a RemoteFile Resource\\nIn this example, the input is a RemoteFile resource. Otherwise, this is very similar to the previous example with an input that downloads a file that is then uploaded and an optional FileSpec output updated for the uploaded file.\\n **UploadArtifact**\\n[code]\\n    pipelines: \\n      - name: uploadArtifactPipeline\\n        steps:\\n          - name: uploadArtifactStep\\n            type: UploadArtifact\\n            configuration:\\n              targetPath: my-repository/myDirectory/myFile.txt\\n              integrations:\\n                - name: myArtifactoryIntegration\\n              inputResources:\\n                - name: myInputRemoteFile\\n              outputResources:\\n                - name: myOutputFileSpec\\n    \\n[/code]\\n###### Publish Build Info and Trigger Xray Scan\\nIn this example, build info is published as part of the UploadArtifact step and an Xray scan is triggered.\\n **UploadArtifact**\\n[code]\\n    pipelines: \\n      - name: uploadArtifactPipeline\\n        steps:\\n          - name: uploadArtifactStep\\n            type: UploadArtifact\\n            configuration:\\n              targetPath: my-repository/myDirectory/myFile.txt\\n              autoPublishBuildInfo: true\\n              forceXrayScan: true\\n              integrations:\\n                - name: myArtifactoryIntegration\\n              inputResources:\\n                - name: myFileSpec\\n              outputResources:\\n                            - name: myBuildInfo\\n    \\n[/code]\\n##### How it Works\\nWhen you use the **UploadArtifact** native step in a pipeline, it performs the following functions in the background:\\n  * jfrog rt config (configure JFrog CLI with the integration listed in the yaml)\\n  * jfrog rt use (configure JFrog CLI to use the config for the integration listed in the yaml)\\n  * mkdir (create a directory to use as the root of relative paths in the following actions)\\n  * cp (copy the FileSpec, RemoteFile, or GitRepo files to the new directory, limit one of each input type)\\n  * jfrog rt upload (upload the Artifact)\\n  * write_output (update the FileSpec output resource with the uploaded pattern and properties)\\n  * add_run_variables (save information in run state for future steps to reference)\\n  * jfrog rt build-collect-env (collect the build environment, preparing for build publish)\\n  * jfrog rt build-publish (publish the build, only if autoPublishBuildInfo is true)\\n  * write_output (update the BuildInfo output resource with the published name/number)\\n  * jfrog rt build-scan (if forceXrayScan is true)\\n  * add_run_files (adds build info to run state)\\n\\n\\n\\n Document url for reference - https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>conditional-workflows</td>\n",
       "      <td>Conditional workflow in Pipelines enables you to choose if a step executes or skips based on certain conditions set for the previous upstream step. This means, when the workflow reaches a conditional step, it can choose different workflow paths based on the steps status. This provides more flexibility in the execution logic of a pipeline.\\n### Note\\nConditional workflow can be applied to any Pipelines step.\\n#### Step Status Conditional Workflow\\nWith the `status` conditional workflow, you can configure a step to execute only if an input steps status, during its current run, is satisfied. You can configure any number of statuses for a step.\\n **YAML Schema**\\n[code]\\n        steps:\\n          - name: &lt;step_name&gt;\\n            type: &lt;step_type&gt;\\n            configuration:\\n                      allowFailure: boolean         #optional\\n              inputSteps:\\n                - name: &lt;step_name&gt;\\n                  status:\\n                    - &lt;terminal_status&gt;\\n                    - &lt;terminal_status&gt;\\n                    - &lt;terminal_status&gt;\\n[/code]\\n### Note\\nIt is important to note that the status of an input step in the current run only is considered for conditional workflows. If a step is not part of the current run, it is always assumed that the condition for that input step is met.\\n##### Adding Conditional Workflow for Steps\\nTo add a conditional workflow for a step:\\n  1. In the `inputSteps` section of a step, add the `status` property.\\n  2. Add any of these values:\\n    * `success`\\n    * `failure`\\n    * `error`\\n    * `cancelled`\\n    * `skipped`\\n    * `unstable`\\n    * `timeout`\\n### Note\\nEnsure that the values are in lowercase and use the same spelling as shown above. Any deviation from this will cause the pipeline source sync to fail.\\n **Example** : In this example:\\n    * step_B has only one status: `success`\\n    * step_C has multiple statuses: `failure`, `skipped`, `cancelled`\\n[code]          - name: step_A\\n            type: Bash\\n            configuration:\\n                      allowFailure: boolean         #optional\\n              inputSteps:\\n                - name: step_B\\n                  status:\\n                    - success\\n                - name: step_C\\n                  status:\\n                    - failure\\n                    - skipped\\n                    - cancelled\\n[/code]\\n  3.  **allowFailure**\\n **Optional** : If you do not want a particular step to contribute to the final status of the run, you can add `allowFailure: true` to the `configuration` section of that step. When this option is used, even when a step fails or is skipped, the final status of the run is not affected.\\nFor example, a pipeline contains two steps S1 and S2:  \\n    *  **Scenario 1** : Step S2 is a cleanup step and its status is irrelevant. The overall run status should be determined by S1s status and S2s status should be ignored. In this case, add `allowFailure: true` to S2, since this is purely a cleanup step and only S1s status should be taken into consideration.\\n    *  **Scenario 2** : Step S1 has been configured to fail as part of the workflow. However S2 runs even if S1 fails and the run is not to be considered a failure. The runs final status should mirror S2s status since S1s status does not interrupt the flow. In this case, add `allowFailure: true` to S1 since S1s failure is a known possibility and expected, and that should not affect the final status of the run.\\n\\n\\nFor more examples, see allowFailure Examples.\\n#### Run Variable Conditional Workflow\\nCreate a condition based on the values of `add_run_variables` environment variable, so that a step can be skipped based on dynamically set variables before it gets assigned to a node.\\n### Note\\nWhen using a `condition`, boolean values must be enclosed in quotes.\\n **Examples** :\\n  * `condition: 'trigger == \"true\"'`\\n  * `condition: \"trigger == 'true'\"`\\n  * `condition: trigger == 'true'`\\n  * `condition: trigger == \"true\"`\\n\\n\\n### Note\\nPipelines environment variables cannot be added as a condition.Pipelines Environment Variables\\n **YAML Schema**\\n[code]\\n        steps:\\n          - name: &lt;step_name&gt;\\n            type: &lt;step_type&gt;\\n            execution:\\n              onExecute:\\n                - add_run_variables 'key=value'\\n          - name: &lt;step_name&gt;\\n            type: &lt;step_type&gt;\\n            configuration:\\n              condition: 'key == value' // Any logical boolean expression that results in a boolean\\n              inputSteps:\\n                - name: &lt;step_name&gt;\\n[/code]\\n **Example**\\n[code]\\n    pipelines:\\n      - name: Example\\n        steps:\\n          - name: step1\\n            type: Bash\\n            execution:\\n              onExecute:\\n                - echo 'step1'\\n                - add_run_variables 'var1=1'\\n          - name: step2\\n            type: Bash\\n            configuration:\\n              condition: 'var1 == 1' // Any logical boolean expression that results to a boolean\\n              inputSteps:\\n                - name: step1\\n            execution:\\n              onExecute:\\n                - echo 'success'\\n[/code]\\n#### Environment Variables Conditional Workflow\\nCreate a conditional workflow based on environment variables defined in the configuration section of your pipelines YAML file. The step executes when the declared condition is met.\\n **Example**\\n[code]\\n    pipelines:\\n      - name: myPipelines\\n        configuration:\\n          environmentVariables:\\n            readOnly:\\n              new_env:\\n                default: 1\\n                allowCustom: true\\n        steps:\\n          - name: step1\\n            type: Bash\\n            configuration:\\n              environmentVariables:\\n                  new_env:\\n                    default: 2\\n                    #allowCustom: true\\n              condition: new_env == 2\\n            execution:\\n              onExecute:\\n                - echo $new_env\\n          - name: step2\\n            type: Bash\\n            configuration: \\n              condition: new_env == 1\\n              inputSteps:\\n                - name: step1\\n            execution:\\n              onExecute:\\n                - echo 'success'\\n[/code]\\n#### newVersionOnly Conditional Workflow\\nWhenever a resource undergoes a change, its version is updated and the dependent step is triggered. This is the default behavior for all input resources. To skip steps in a run when input resources are not updated, add the `newVersionOnly` tag and set it as `true`. During a run, the step is triggered only when the resource is updated. If the resource is not updated, the step is skipped and all the downstream steps are skipped as well.\\n **Example 1 - newVersionOnly**\\n[code]\\n    pipelines:\\n      - name: java_pipeline\\n        steps:\\n          - name: step_1\\n            type: Bash\\n            configuration:\\n              inputResources:\\n                - name: my_app_repo\\n                - newVersionOnly: true\\n            execution:\\n              onExecute:\\n                - pushd $res_my_app_repo_resourcePath\\n                - ./execute.sh\\n                - popd\\n[/code]\\n **Example 2 - newVersionOnly**\\n[code]\\n    resources:\\n      - name: new_resource\\n        type: PropertyBag\\n        configuration:\\n          runNumber: 0\\n    \\n    pipelines:\\n      - name: pipeline_01\\n        steps:\\n          - name: step_input\\n            type: Bash\\n            configuration:\\n              outputResources:\\n                - name: new_resource\\n            execution:\\n              onExecute:\\n                #- write_output new_resource runNumber=${run_number}\\n                - echo \"test\"\\n    \\n          - name: step1      \\n            type: Bash\\n            configuration:\\n              inputResources:\\n                - name: new_resource\\n                  newVersionOnly: true\\n            execution:\\n              onExecute:\\n                - echo \"test\"\\n    \\n          - name: step2\\n            type: Bash\\n            configuration:\\n              inputResources:\\n                - name: new_resource\\n            execution:\\n              onExecute:\\n                - echo \"test\"\\n[/code]  \\n#### Viewing Run Logs\\nWhen you run a pipeline, in addition to the other logs, the logs for steps with conditional workflow provide information about the skipped steps.\\nTo view these logs, go to the Pipeline Run Logs view, click the skipped step to display the logs for the current run.  \\n#### Examples\\n##### Example 1\\nIn this example:\\n  * Step B is triggered only if step A succeeds (default behavior), and step C is triggered only if step A is in failed, error, or timeout status.\\n  * Step B does not need any special configuration as the default behavior is to trigger a dependent step if the previous step succeeds.\\n  * Step A also does not need any special configuration since the step itself does not decide the downstream workflow path.\\n\\n  \\n **YAML**\\n[code]\\n      - name: demo_conditional\\n        steps:\\n          - name: step_A\\n            type: Bash\\n            configuration:\\n              inputResources:\\n                - name: script_conditional\\n            execution:\\n              onExecute:\\n                - echo \"Executing step_A\"\\n                - printenv\\n         \\n          - name: step_B\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n                - name: step_A\\n            execution:\\n              onExecute:\\n                - echo \"Executing step_B\"\\n                - printenv\\n    \\n          - name: step_C\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n                - name: step_A\\n                  status:\\n                    - failure\\n                    - error\\n                    - timeout\\n            execution:\\n              onExecute:\\n                - echo \"Executing step_C\"\\n                - printenv\\n[/code]\\n##### Example 2\\nIn this example, Step S is triggered if Step Q succeeds and Step R fails. However, if both Step Q and Step R succeed or fail during the run, Step S is not triggered and it is skipped.  \\n **YAML**\\n[code]\\n          - name: step_S\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n                - name: step_Q\\n                  status:\\n                    - success\\n                - name: step_R\\n                  status:\\n                    - failure\\n            execution:\\n              onExecute:\\n                - echo \"Executing step_S\"\\n                - printenv\\n[/code]\\n##### Example 3\\nIn this example, Step O is triggered if Step M succeeds and Step N fails. However, since Step N is not part of the current run, Step O is triggered when Step M succeeds and Step N's status is ignored.  \\n **YAML**\\n[code]\\n          - name: step_O\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n                - name: step_M\\n                  status:\\n                    - success\\n                - name: step_N\\n                  status:\\n                    - failure\\n            execution:\\n              onExecute:\\n                - echo \"Executing step_O\"\\n                - printenv\\n[/code]\\n##### Example 4 - Using Environment Variable\\nThe `step_&lt;inputStepName&gt;_statusName`, which is an environment variable that is automatically made available at runtime, can be used in conjunction with conditional workflows. This `step_&lt;inputStepName&gt;_statusName` environment variable is useful for fetching the status of any input step, especially when working with Jenkins.\\n **YAML**\\n[code]\\n    resources:\\n      - name: script_gh\\n        type: GitRepo\\n        configuration:\\n          path: jfrog/sample-script\\n          gitProvider: myGithub\\n          branches:\\n            include: ^{{gitBranch}}$\\n    \\n    pipelines:     \\n      - name: simple_jenkins_demo\\n        steps:\\n          - name: jenkins\\n            type: Jenkins\\n            configuration:\\n              inputResources:\\n                - name: script_gh\\n              jenkinsJobName: testPipeline\\n              integrations:\\n                - name: myJenkins\\n          \\n          - name: step_A\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n                - name: jenkins\\n                  status:\\n                    - failure\\n                    - error\\n                    - timeout\\n            execution:\\n              onExecute:\\n                - echo \"Executing step_A\"\\n                - if [ $step_jenkins_statusName == \"failure\" ]; then  echo \"Do something\"; fi\\n                - if [ $step_jenkins_statusName == \"error\" ]; then  echo \"Do something else\"; fi\\n         \\n          - name: simple_conditional_B\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n                - name: jenkins\\n                  status:\\n                    - failure\\n                    - error\\n            execution:\\n              onExecute:\\n                - echo \"Executing simple_conditional_B\"\\n                - printenv\\n    \\n[/code]\\n#### allowFailure Examples\\n##### Example 1\\nStep1 is configured for success and step2 for failure. Step2 is allowed to run when step1 fails and the final status of the run is success.\\n[code]\\n    pipelines:\\n      - name: PIPE_9455_Workflow_03\\n        steps:\\n          - name: step1\\n            type: Bash\\n            execution:\\n              onExecute:\\n                - echo 'step1'\\n          - name: step2\\n            type: Bash\\n            configuration:\\n              allowFailure: true\\n              inputSteps:\\n              - name: step1\\n                status:\\n                  - success\\n                  - error\\n                  - failure\\n                  - timeout\\n            execution:\\n              onExecute:\\n                - echo 'success'\\n                - exit 1\\n[/code]\\n##### Example 2\\nStep1 is configured for failure and step2 for success. Step2 is allowed to run when step1 fails and the final status of the run is success.\\n[code]\\n    pipelines:\\n      - name: PIPE_9455_Workflow_05\\n        steps:\\n          - name: step1\\n            type: Bash\\n            configuration:\\n              allowFailure: true\\n            execution:\\n              onExecute:\\n                - echo 'step1'\\n                - exit 1\\n          - name: step2\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n              - name: step1\\n                status:\\n                  - success\\n                  - error\\n                  - failure\\n                  - timeout\\n            execution:\\n              onExecute:\\n                - echo 'success'\\n[/code]\\n##### Example 3\\nStep1 is configured for success and step2 for failure. When triggered, the final status of the run is failure.\\n[code]\\n    pipelines:\\n      - name: PIPE_9455_Workflow_03\\n        steps:\\n          - name: step1\\n            type: Bash\\n            configuration:\\n              allowFailure: true\\n            execution:\\n              onExecute:\\n                - echo 'step1'\\n          - name: step2\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n              - name: step1\\n                status:\\n                  - success\\n                  - error\\n                  - failure\\n                  - timeout\\n            execution:\\n              onExecute:\\n                - echo 'failure'\\n                - exit 1\\n[/code]\\n\\n Document url for reference - https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Title  \\\n",
       "0          jfrog-pipelines   \n",
       "78             dockerbuild   \n",
       "101         uploadartifact   \n",
       "234  conditional-workflows   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      PiplineProcess  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             JFrog Pipelines offers JFrog Platform customers three vital capabilities: end-to-end automation (CI/CD), workflow and tool orchestration, and the optimization of the JFrog toolset functionality in use. Consistent with JFrogs customer-centric product philosophy, Pipelines is enterprise-ready and universal.\\n### Workflow Automation\\nA pipeline is an event-driven automated workflow for executing a set of DevOps activities (CI, deployments, infrastructure provisioning, etc). It is composed of a sequence of interdependent **steps** which execute discrete functions. Steps act on **resources** , which hold the information needed to execute (files, key-value pairs, etc).\\nDevelopers can create pipelines easily with a simple declarative YAML-based language. While each step in a pipeline executes in a stateless runtime environment, Pipelines provides facilities to manage state and step outputs across the workflow so that all dependent steps can access the information they need from upstream steps in order to execute. This helps coordinate activities centrally across diverse DevOps tools and teams without custom DIY scripts.\\nWorkflows can be configured for a variety of scenarios, including:\\n  * Continuous Integration for your applications\\n  * Continuous Delivery workflows that connect all your CI/CD and DevOps activities across tools and functional silos\\n  * Automate IT Ops workflows like infrastructure provisioning, security patching, and image building\\n\\n\\n### Get up and running with JFrog Pipelines\\nIn this section, you will find information to get you started whether you are a new user or an existing user.\\n  * If you do not yet have a subscription, get started with trial subscription of the JFrog Platform on the Cloud.\\n  * If you are a new user, get started with the onboarding videos for JFrog Pipelines.Onboarding Best Practices: JFrog Pipelines\\n\\n\\n### Features\\n#### Pipelines as Code\\nDefine your automated workflow through code, using a domain specific language in a YAML file of key-value pairs that you can create and maintain with your favorite text editor.\\n#### Real Time Visibility\\nJFrog Pipelines renders your pipeline definition as an interactive diagram, helping you to see the flow of tasks and their inter-dependencies, as well as view the success record of any runs that were performed.\\n#### Universal\\nConnect your pipeline automation to your source code repositories in a version control system (such as GitHub or BitBucket) to automatically trigger execution on any new submission (commit) of a code change. Connect to other popular tools through your credentials for storage, issue-tracking, notification, orchestration and more through a library of integrations.\\n#### Native Integration with Artifactory\\nJFrog Pipelines is designed to be used with Artifactory, with built-in directives for pushing artifacts, performing builds, pushing build information, image scanning, and build promotion.\\n#### Integration with JFrog Platform\\nJFrog Pipelines is designed as an integral part of the JFrog platform, including scanning artifacts/builds through Xray, the creation and delivery of release bundles through JFrog Distribution, for a complete end-to-end SDLC pipeline from commit to production runtime.\\n#### Security First\\nFine-grained permissions and access control limit who can access workflows. Centralized, encrypted storage of credentials and keys help ensure secrets stay safe.\\n#### Enterprise-Ready\\nManage multiple execution nodes using a single installation of Pipelines and automatically distribute Pipeline execution across them for scale and speed.\\n### Watch the Screencast\\n\\n Document url for reference - https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps  \n",
       "78                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    The **DockerBuild** native step performs a build to produce a Docker image from a Dockerfile in a GitRepo source repository resource.\\nIn the step configuration, you must provide the name ( `dockerFileName` ) and directory ( `dockerFileLocation` ) of the Dockerfile that contains the command to be processed by a `docker build` command, as well as the name ( `dockerImageName` ) and tag ( `dockerImageTag` ) of the resulting image. The image is built on the build node, and information about that image is stored in the run state.\\nTo build a Docker image that relies on a private base image:\\n  1. Define the base image as an Image resource, with `autoPull` set to `true`.\\n  2. Specify the Image resource as one of the `inputResources` of the DockerBuild step.\\n\\n\\nTo include artifacts in the Docker image that are not part of the GitRepo source repository:\\n  1. Define a FileSpec resource that specifies the files to include from Artifactory.\\n  2. Specify the FileSpec resource as one of the `inputResources`of the DockerBuild step.\\n\\n\\n### Proper usage of DockerBuild step\\nDockerBuild and DockerPush steps must be assigned to the same `affinityGroup` to share state. If this is not done, the output of DockerBuild will not be available for DockerPush. For more information on using `affinityGroup`, see Running multiple steps on the same build node.\\n### Docker Build and Push Quickstart\\nThis Docker Build and Push quickstart demonstrates the definition of a pipeline that uses the DockerBuild and DockerPush native steps to build a single Docker Image, push it to Artifactory, and then publish the BuildInfo.\\n##### YAML Schema\\nThe YAML schema for DockerBuild native step is as follows:\\n **DockerBuild**\\n[code]\\n    pipelines: \\n      - name: <string>\\n        steps:\\n          - name: <string>\\n            type: DockerBuild\\n            configuration:\\n              #inherits all the tags from bash\\n              affinityGroup:       <string>\\n              dockerFileLocation:  <string>\\n              dockerFileName:      <string>\\n              dockerImageName:     <string>\\n              dockerImageTag:      <string>\\n              dockerOptions:       <string>\\n    \\n              integrations:\\n                - name:            <artifactory or docker registry integration>  # required\\n    \\n              inputResources:\\n                - name:             <GitRepo resource>        # required, git repository containing your Dockerfile\\n                - name:             <Image resource>          # optional base image\\n                - name:             <FileSpec resource>       # optional\\n    \\n            execution:\\n              onStart:\\n                - echo \"Preparing for work...\"\\n              onSuccess:\\n                - echo \"Job well done!\"\\n              onFailure:\\n                - echo \"uh oh, something went wrong\"\\n              onComplete: #always\\n                - echo \"Cleaning up some stuff\"\\n[/code]\\n##### Tags\\n###### name\\nAn alphanumeric string (underscores are permitted) that identifies the step.\\n###### type\\nMust be `DockerBuild` for this step type.\\n###### configuration\\nSpecifies all configuration selections for the step's execution environment. This step inherits the Bash/ PowerShell step configuration tags, including these pertinenttags:\\nTag\\n **Description of usage**\\nRequired/Optional  \\n`affinityGroup`\\nMust specify an affinity group string that is the same as specified in a subsequent DockerPush step.\\nOptional  \\n`inputResources`\\nMust specify:\\n  * a GitRepo resource (that contains the Dockerfile)\\n\\n\\nOptionally, you may also specify:\\n  * One or more Image resources to pull base images used in the build or to trigger this build.\\n  * One or more FileSpec resources that specify what files to include in the build context. These files are automatically copied to `dockerFileLocation`.\\n\\n\\nRequired/Optional  \\nIn addition, these tags can be defined to support the step's native operation:\\n### Tags derived from Bash\\nAll native steps derive from the Bash step. This means that all steps share the same base set of tags from Bash, while native steps have their own additional tags as well that support the step's particular function. So it's important to be familiar with the Bash step definition, since it's the core of the definition of all other steps.\\nTag\\n **Description of usage**\\nRequired/Optional  \\n`dockerFileLocation`\\nDirectory containing the Dockerfile, which is the file that has Docker build configuration. This file is also used as the context for the Docker build. The path provided should be relative to the root of the input GitRepo repository. If no location is provided, the default is the root of the GitRepo repository.\\nRequired  \\n`dockerFileName`\\nName of the Dockerfile.\\nRequired  \\n`dockerImageName`\\nThe name of the Docker image to create. This can be set using environment variables or triggering a run using parameters.\\nRequired  \\n`dockerImageTag`\\nThe tag for the Docker image to create. This can be set using environment variables or triggering a run using parameters.\\nRequired  \\n`dockerOptions`\\nAdditional options for the docker build command.\\nOptional  \\n###### execution\\nDeclares collections of shell command sequences to perform for pre- and post-execution phases:\\nTag\\n **Description of usage**\\nRequired/Optional  \\n`onStart`\\nCommands to execute in advance of the native operation\\nOptional  \\n`onSuccess`\\nCommands to execute on successful completion\\nOptional  \\n`onFailure`\\nCommands to execute on failed completion\\nOptional  \\n`onComplete`\\nCommands to execute on any completion\\nOptional  \\nThe actions performed for the `onExecute` phase are inherent to this step type and may not be overridden.\\n##### Examples\\nThe following examples use a GoLang Git repository represented by a GitRepo resource named `gosvc_app` to create a Docker image that is published to Artifactory. They assume that an Artifactory integration named `MyArtifactory` has been created, and that the Artifactory instance has a Docker repository mapped to `docker.artprod.company`.\\n  * These examples require an Artifactory Integration and a GitHub Integration.GitHub Integration\\n  * The Pipelines DSL for a similar example is available in this repository in the JFrog GitHub account.\\n  * For a full tutorial, see Pipeline Example: Docker Build and Push.\\n\\n\\nThe following resources declarations support these examples. Not all of these resources are used in all examples.\\n###### Resources\\n[code]\\n    resources:\\n    # Application source repository\\n      - name: gosvc_app\\n        type: GitRepo\\n        configuration:\\n          gitProvider: myGithub\\n          path: myuser/myrepo                   # replace with your repository name\\n          branches:\\n            include: master\\n    \\n    # Docker image in an Artifactory repository\\n      - name: base_image\\n        type: Image\\n        configuration:\\n          registry: myArtifactory\\n          sourceRepository: docker-local        # replace with your repository name\\n          imageName: docker.artprod.mycompany.com/baseimage\\n          imageTag: latest\\n          autoPull: true\\n    \\n    # Files in an Artifactory repository\\n      - name: icon_files\\n        type: FileSpec\\n        configuration:\\n          sourceArtifactory: myArtifactory\\n          pattern: my-local-repo/all-my-images/\\n          target: icons/\\n[/code]\\n###### Build a Docker image from a source repository\\nThis example builds a Docker image to a Docker registry in Artifactory. The tag for the image is set to the pipeline's run number.\\n[code]\\n    pipelines:\\n      - name: demo_pipeline\\n        steps:\\n          - name: bld_image\\n            type: DockerBuild\\n            configuration:\\n              dockerFileLocation: .\\n              dockerFileName: Dockerfile\\n              dockerImageName: docker.artprod.mycompany.com/gosvc    # replace with your fully qualified Docker registry/image name\\n              dockerImageTag: ${run_number}\\n              inputResources:\\n                - name: gosvc_app\\n              integrations:\\n                - name: MyArtifactory\\n[/code]\\n###### Build a Docker image with dockerOptions\\nThis example demonstrates use of the `dockerOptions` tag to set the `build-arg` option for the Docker command. An environment variable named `build_number_env_variable` is dynamically set to the pipeline's run number. The example assumes the environment variable is used in the Dockerfile commands.\\n[code]\\n    pipelines:\\n      - name: demo_pipeline\\n        steps:\\n          - name: bld_image\\n            type: DockerBuild\\n            configuration:\\n              dockerFileLocation: .\\n              dockerFileName: Dockerfile\\n              dockerImageName: docker.artprod.mycompany.com/gosvc   # replace with your fully qualified Docker registry/image name\\n              dockerImageTag: ${run_number}\\n              dockerOptions: --build-arg build_number_env_variable=${run_number}           \\n              inputResources:\\n                - name: gosvc_app\\n              integrations:\\n                - name: MyArtifactory\\n[/code]\\n###### Build a Docker image with a private base image\\nThis example builds a Docker image that relies on a private base image stored in an Artifactory Docker repository.\\n[code]\\n    pipelines:\\n      - name: demo_pipeline\\n        steps:\\n          - name: bld_image\\n            type: DockerBuild\\n            configuration:\\n              dockerFileLocation: .\\n              dockerFileName: Dockerfile\\n              dockerImageName: docker.artprod.mycompany.com/gosvc       # replace with your fully qualified Docker registry/image name\\n              dockerImageTag: ${run_number}\\n              inputResources:\\n                - name: gosvc_app\\n                - name: base_image\\n              integrations:\\n                - name: MyArtifactory\\n[/code]\\n###### Build a Docker image with files outside the current path\\nThis example demonstrates building a Docker image that includes files outside of the current path. It pulls icon files stored in an Artifactory repository for integration art named `my-local-repo`. It is assumed that the Dockerfile has a command that will include the files in `/icons` into the image.\\n[code]\\n    pipelines:\\n      - name: demo_pipeline\\n        steps:\\n          - name: bld_image\\n            type: DockerBuild\\n            configuration:\\n              dockerFileLocation: .\\n              dockerFileName: Dockerfile\\n              dockerImageName: docker.artprod.mycompany.com/gosvc         # replace with your fully qualified Docker registry/image name\\n              dockerImageTag: ${run_number}\\n              inputResources:\\n                - name: gosvc_app\\n                - name: icon_files\\n              integrations:\\n                - name: MyArtifactory\\n[/code]\\n##### How it Works\\nWhen you use the **DockerBuild** native step in a pipeline, it performs the following functions in the background:\\n  * cp (if there is a FileSpec input, copy those files to the root of the cloned GitRepo input)\\n  * docker build\\n  * add_run_variables (add several variables that are later used when pushing the Docker image or publishing build info)\\n  * jfrog rt build-collect-env (collect environment information to be later published as part of build info)\\n  * add_run_files (save information collected for build info)\\n\\n\\n\\n Document url for reference - https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps  \n",
       "101                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       The **UploadArtifact** native step uploads artifacts to Artifactory. Optionally, it can also publish build information to Artifactory and trigger Xray scans.\\nThis step utilizes the JFrog CLI to upload an artifact to Artifactory. The file(s) may be provided in a FileSpec, if already in Artifactory, or RemoteFile or GitRepo input.\\n##### YAML Schema\\nThe YAML schema for UploadArtifact native step is as follows:\\n **UploadArtifact**\\n[code]\\n    pipelines: \\n      - name:   <string>\\n        steps:\\n          - name: <string>\\n            type: UploadArtifact\\n            configuration:\\n              targetPath:           <string>  #required\\n              sourcePath:           <string>  #optional\\n              properties:           <string>  #optional\\n                      regExp:                       <boolean> #optional\\n              flat:                 <boolean> #optional\\n                      module:                       <string>  #optional\\n                      deb:                  <string>  #optional\\n                      recursive:                <boolean>     #optional\\n                      dryRun:                       <boolean> #optional\\n              symlinks:                     <boolean> #optional\\n              explode:                      <boolean> #optional\\n              exclusions:               <string>      #optional\\n              includeDirs:              <boolean>     #optional\\n              syncDeletes:              <string>      #optional\\n              forceXrayScan:                <boolean> #optional\\n              failOnScan:           <boolean>   # default true\\n                      autoPublishBuildInfo: <boolean> #optional\\n              inputResources:\\n                            - name: myGitRepo       \\n                            - name: artifactoryFileSpec     \\n                - name: myRemoteFile        \\n                      outputResources:\\n                - name: myFileSpec\\n                            - name: myBuildInfo\\n              integrations:\\n                            - name: myArtifactory \\n            execution:\\n              onStart:\\n                - echo \"Preparing for work...\"\\n              onSuccess:\\n                - echo \"Job well done!\"\\n              onFailure:\\n                - echo \"uh oh, something went wrong\"\\n              onComplete: #always\\n                - echo \"Cleaning up some stuff\"\\n    \\n[/code]\\n##### Tags\\n###### name\\nAn alphanumeric string (underscores are permitted) that identifies the step.\\n###### type\\nMust be `UploadArtifact` for this step type.\\n###### configuration\\nSpecifies all configuration selections for the step's execution environment. This step inherits the Bash/ PowerShell step configuration tags, including these pertinent tags:\\nTag\\n **Description of usage**\\nRequired/Optional  \\n`integrations`\\nMust specify an  Artifactory Integration.\\nRequired  \\n`inputResources`\\nMay specify a GitRepo, FileSpec, or RemoteFile resource containing the file(s) to be uploaded. One of each type may be specified.\\nOptional  \\n`outputResources`\\nMust specify a BuildInfo resource if `autoPublishBuildInfo` is set as `true`.\\nIf `JFROG_CLI_BUILD_NAME` or `JFROG_CLI_BUILD_NUMBER` is set as an environment variable for the pipeline or the step, that name and/or number is used for the output BuildInfo. Otherwise, the default `buildName` and `buildNumber` are `$pipeline_name` and `$run_number.`\\nMay also specify a FileSpec resource to be updated with the pattern and properties of the uploaded Artifact.\\nMay be required  \\nIn addition, these tags can be defined to support the step's native operation:\\nTag\\n **Description of usage**\\nRequired/Optional  \\ntargetPath\\nPath to upload the files, including repository name.\\nRequired  \\n`sourcePath`\\nFiles to upload. If this is a relative path pattern, it is relative to the root of a GitRepo/FileSpec/RemoteFile input.\\nDefault is `*` when `regExp` is `false` and `.*` when `regExp` is `true`.\\nOptional  \\n`properties`\\nSemi-colon separated properties for the uploaded artifact. For example: `myFirstProperty=one;mySecondProperty=two`.\\nProperties `pipelines_step_name`, `pipelines_run_number`, `pipelines_step_id`, `pipelines_pipeline_name`, `pipelines_step_url`, `pipelines_step_type`, and `pipelines_step_platform` will also be added.\\nOptional  \\n`regExp`\\nWhen set as `true`, regular expressions are used in other parameters, such as `sourcePath`, instead of wildcards. Expressions must be in parentheses.\\nDefault is `false`.\\nOptional  \\n`flat`\\nWhen set as `true`, the uploaded files are flattened, removing the directory structure.\\nDefault is `false`.\\nOptional  \\n`module`\\nA module name for the Build Info.\\nOptional  \\n`deb`\\nA `distribution/component/architecture` for Debian packages. If the distribution, component, or architecture includes a / it must be double-escaped, For example: `distribution/my\\\\\\/component/architecture` for a `my/component` component.\\nOptional  \\n`recursive`\\nWhen set as `false`, do not upload any matches in subdirectories.\\nDefault is true.\\nOptional  \\n`dryRun`\\nWhen set as `true`, nothing is uploaded.\\nDefault is `false`.\\nOptional  \\n`symlinks`\\nWhen set as `true`, symlinks matching the other criteria are uploaded.\\nDefault is `false`.\\nOptional  \\n`explode`\\nWhen set as `true` and the uploaded Artifact is an archive, the archive is expanded.\\nDefault is `false`.\\nOptional  \\n`exclusions`\\nSemi-colon separated patterns to exclude.\\nOptional  \\n`includeDirs`\\nWhen set as `true`, empty directories matching the criteria are uploaded.\\nDefault is `false`.\\nOptional  \\n`syncDeletes`\\nA path under which to delete any existing files in Artifactory.\\nOptional  \\n`forceXrayScan`\\nWhen set as `true`, forces an Xray scan after publishing to Artifactory.\\nDefault is `false`.\\nOptional  \\n`failOnScan`\\nWhen set as `true`, and when the Xray Policy Rule  Fail Build checkbox is checked, a failed Xray scan will result in a failure of the step.Creating Xray Policies and Rules\\nDefault is `true`.\\nOptional  \\n`autoPublishBuildInfo`\\nWhen set as `true`, publishes build info to Artifactory.\\nDefault is `false`.\\nOptional  \\n###### execution\\nDeclares collections of shell command sequences to perform for pre- and post-execution phases:\\nTag\\n **Description of usage**\\nRequired/Optional  \\n`onStart`\\nCommands to execute in advance of the native operation\\nOptional  \\n`onSuccess`\\nCommands to execute on successful completion\\nOptional  \\n`onFailure`\\nCommands to execute on failed completion\\nOptional  \\n`onComplete`\\nCommands to execute on any completion\\nOptional  \\nThe actions performed for the `onExecute` phase are inherent to this step type and may not be overridden.\\n### Note\\n`onExecute`, `onStart`, `onSuccess`, `onFailure`, and `onComplete` are reserved keywords. Using these keywords in any other context in your execution scripts can cause unexpected behavior.\\n##### Examples\\nThe following examples show a few ways in which a UploadArtifact step can be configured.\\n###### Uploading an Artifact to Another Repository using a FileSpec Resource\\nThe most basic form of UploadArtifact. Uses all default values. This step will download the file matching the FileSpec and upload it to the location in `targetPath`. The optional output FileSpec resource will be updated with the `targetPath` and the default properties added to the uploaded artifact.\\n **UploadArtifact**\\n[code]\\n    pipelines: \\n      - name: uploadArtifactPipeline\\n        steps:\\n          - name: uploadArtifactStep\\n            type: UploadArtifact\\n            configuration:\\n              targetPath: my-repository/myDirectory/myFile.txt\\n              integrations:\\n                - name: myArtifactoryIntegration\\n              inputResources:\\n                - name: myInputFileSpec\\n              outputResources:\\n                - name: myOutputFileSpec\\n    \\n[/code]\\n###### Uploading an Artifact from a RemoteFile Resource\\nIn this example, the input is a RemoteFile resource. Otherwise, this is very similar to the previous example with an input that downloads a file that is then uploaded and an optional FileSpec output updated for the uploaded file.\\n **UploadArtifact**\\n[code]\\n    pipelines: \\n      - name: uploadArtifactPipeline\\n        steps:\\n          - name: uploadArtifactStep\\n            type: UploadArtifact\\n            configuration:\\n              targetPath: my-repository/myDirectory/myFile.txt\\n              integrations:\\n                - name: myArtifactoryIntegration\\n              inputResources:\\n                - name: myInputRemoteFile\\n              outputResources:\\n                - name: myOutputFileSpec\\n    \\n[/code]\\n###### Publish Build Info and Trigger Xray Scan\\nIn this example, build info is published as part of the UploadArtifact step and an Xray scan is triggered.\\n **UploadArtifact**\\n[code]\\n    pipelines: \\n      - name: uploadArtifactPipeline\\n        steps:\\n          - name: uploadArtifactStep\\n            type: UploadArtifact\\n            configuration:\\n              targetPath: my-repository/myDirectory/myFile.txt\\n              autoPublishBuildInfo: true\\n              forceXrayScan: true\\n              integrations:\\n                - name: myArtifactoryIntegration\\n              inputResources:\\n                - name: myFileSpec\\n              outputResources:\\n                            - name: myBuildInfo\\n    \\n[/code]\\n##### How it Works\\nWhen you use the **UploadArtifact** native step in a pipeline, it performs the following functions in the background:\\n  * jfrog rt config (configure JFrog CLI with the integration listed in the yaml)\\n  * jfrog rt use (configure JFrog CLI to use the config for the integration listed in the yaml)\\n  * mkdir (create a directory to use as the root of relative paths in the following actions)\\n  * cp (copy the FileSpec, RemoteFile, or GitRepo files to the new directory, limit one of each input type)\\n  * jfrog rt upload (upload the Artifact)\\n  * write_output (update the FileSpec output resource with the uploaded pattern and properties)\\n  * add_run_variables (save information in run state for future steps to reference)\\n  * jfrog rt build-collect-env (collect the build environment, preparing for build publish)\\n  * jfrog rt build-publish (publish the build, only if autoPublishBuildInfo is true)\\n  * write_output (update the BuildInfo output resource with the published name/number)\\n  * jfrog rt build-scan (if forceXrayScan is true)\\n  * add_run_files (adds build info to run state)\\n\\n\\n\\n Document url for reference - https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps  \n",
       "234  Conditional workflow in Pipelines enables you to choose if a step executes or skips based on certain conditions set for the previous upstream step. This means, when the workflow reaches a conditional step, it can choose different workflow paths based on the steps status. This provides more flexibility in the execution logic of a pipeline.\\n### Note\\nConditional workflow can be applied to any Pipelines step.\\n#### Step Status Conditional Workflow\\nWith the `status` conditional workflow, you can configure a step to execute only if an input steps status, during its current run, is satisfied. You can configure any number of statuses for a step.\\n **YAML Schema**\\n[code]\\n        steps:\\n          - name: <step_name>\\n            type: <step_type>\\n            configuration:\\n                      allowFailure: boolean         #optional\\n              inputSteps:\\n                - name: <step_name>\\n                  status:\\n                    - <terminal_status>\\n                    - <terminal_status>\\n                    - <terminal_status>\\n[/code]\\n### Note\\nIt is important to note that the status of an input step in the current run only is considered for conditional workflows. If a step is not part of the current run, it is always assumed that the condition for that input step is met.\\n##### Adding Conditional Workflow for Steps\\nTo add a conditional workflow for a step:\\n  1. In the `inputSteps` section of a step, add the `status` property.\\n  2. Add any of these values:\\n    * `success`\\n    * `failure`\\n    * `error`\\n    * `cancelled`\\n    * `skipped`\\n    * `unstable`\\n    * `timeout`\\n### Note\\nEnsure that the values are in lowercase and use the same spelling as shown above. Any deviation from this will cause the pipeline source sync to fail.\\n **Example** : In this example:\\n    * step_B has only one status: `success`\\n    * step_C has multiple statuses: `failure`, `skipped`, `cancelled`\\n[code]          - name: step_A\\n            type: Bash\\n            configuration:\\n                      allowFailure: boolean         #optional\\n              inputSteps:\\n                - name: step_B\\n                  status:\\n                    - success\\n                - name: step_C\\n                  status:\\n                    - failure\\n                    - skipped\\n                    - cancelled\\n[/code]\\n  3.  **allowFailure**\\n **Optional** : If you do not want a particular step to contribute to the final status of the run, you can add `allowFailure: true` to the `configuration` section of that step. When this option is used, even when a step fails or is skipped, the final status of the run is not affected.\\nFor example, a pipeline contains two steps S1 and S2:  \\n    *  **Scenario 1** : Step S2 is a cleanup step and its status is irrelevant. The overall run status should be determined by S1s status and S2s status should be ignored. In this case, add `allowFailure: true` to S2, since this is purely a cleanup step and only S1s status should be taken into consideration.\\n    *  **Scenario 2** : Step S1 has been configured to fail as part of the workflow. However S2 runs even if S1 fails and the run is not to be considered a failure. The runs final status should mirror S2s status since S1s status does not interrupt the flow. In this case, add `allowFailure: true` to S1 since S1s failure is a known possibility and expected, and that should not affect the final status of the run.\\n\\n\\nFor more examples, see allowFailure Examples.\\n#### Run Variable Conditional Workflow\\nCreate a condition based on the values of `add_run_variables` environment variable, so that a step can be skipped based on dynamically set variables before it gets assigned to a node.\\n### Note\\nWhen using a `condition`, boolean values must be enclosed in quotes.\\n **Examples** :\\n  * `condition: 'trigger == \"true\"'`\\n  * `condition: \"trigger == 'true'\"`\\n  * `condition: trigger == 'true'`\\n  * `condition: trigger == \"true\"`\\n\\n\\n### Note\\nPipelines environment variables cannot be added as a condition.Pipelines Environment Variables\\n **YAML Schema**\\n[code]\\n        steps:\\n          - name: <step_name>\\n            type: <step_type>\\n            execution:\\n              onExecute:\\n                - add_run_variables 'key=value'\\n          - name: <step_name>\\n            type: <step_type>\\n            configuration:\\n              condition: 'key == value' // Any logical boolean expression that results in a boolean\\n              inputSteps:\\n                - name: <step_name>\\n[/code]\\n **Example**\\n[code]\\n    pipelines:\\n      - name: Example\\n        steps:\\n          - name: step1\\n            type: Bash\\n            execution:\\n              onExecute:\\n                - echo 'step1'\\n                - add_run_variables 'var1=1'\\n          - name: step2\\n            type: Bash\\n            configuration:\\n              condition: 'var1 == 1' // Any logical boolean expression that results to a boolean\\n              inputSteps:\\n                - name: step1\\n            execution:\\n              onExecute:\\n                - echo 'success'\\n[/code]\\n#### Environment Variables Conditional Workflow\\nCreate a conditional workflow based on environment variables defined in the configuration section of your pipelines YAML file. The step executes when the declared condition is met.\\n **Example**\\n[code]\\n    pipelines:\\n      - name: myPipelines\\n        configuration:\\n          environmentVariables:\\n            readOnly:\\n              new_env:\\n                default: 1\\n                allowCustom: true\\n        steps:\\n          - name: step1\\n            type: Bash\\n            configuration:\\n              environmentVariables:\\n                  new_env:\\n                    default: 2\\n                    #allowCustom: true\\n              condition: new_env == 2\\n            execution:\\n              onExecute:\\n                - echo $new_env\\n          - name: step2\\n            type: Bash\\n            configuration: \\n              condition: new_env == 1\\n              inputSteps:\\n                - name: step1\\n            execution:\\n              onExecute:\\n                - echo 'success'\\n[/code]\\n#### newVersionOnly Conditional Workflow\\nWhenever a resource undergoes a change, its version is updated and the dependent step is triggered. This is the default behavior for all input resources. To skip steps in a run when input resources are not updated, add the `newVersionOnly` tag and set it as `true`. During a run, the step is triggered only when the resource is updated. If the resource is not updated, the step is skipped and all the downstream steps are skipped as well.\\n **Example 1 - newVersionOnly**\\n[code]\\n    pipelines:\\n      - name: java_pipeline\\n        steps:\\n          - name: step_1\\n            type: Bash\\n            configuration:\\n              inputResources:\\n                - name: my_app_repo\\n                - newVersionOnly: true\\n            execution:\\n              onExecute:\\n                - pushd $res_my_app_repo_resourcePath\\n                - ./execute.sh\\n                - popd\\n[/code]\\n **Example 2 - newVersionOnly**\\n[code]\\n    resources:\\n      - name: new_resource\\n        type: PropertyBag\\n        configuration:\\n          runNumber: 0\\n    \\n    pipelines:\\n      - name: pipeline_01\\n        steps:\\n          - name: step_input\\n            type: Bash\\n            configuration:\\n              outputResources:\\n                - name: new_resource\\n            execution:\\n              onExecute:\\n                #- write_output new_resource runNumber=${run_number}\\n                - echo \"test\"\\n    \\n          - name: step1      \\n            type: Bash\\n            configuration:\\n              inputResources:\\n                - name: new_resource\\n                  newVersionOnly: true\\n            execution:\\n              onExecute:\\n                - echo \"test\"\\n    \\n          - name: step2\\n            type: Bash\\n            configuration:\\n              inputResources:\\n                - name: new_resource\\n            execution:\\n              onExecute:\\n                - echo \"test\"\\n[/code]  \\n#### Viewing Run Logs\\nWhen you run a pipeline, in addition to the other logs, the logs for steps with conditional workflow provide information about the skipped steps.\\nTo view these logs, go to the Pipeline Run Logs view, click the skipped step to display the logs for the current run.  \\n#### Examples\\n##### Example 1\\nIn this example:\\n  * Step B is triggered only if step A succeeds (default behavior), and step C is triggered only if step A is in failed, error, or timeout status.\\n  * Step B does not need any special configuration as the default behavior is to trigger a dependent step if the previous step succeeds.\\n  * Step A also does not need any special configuration since the step itself does not decide the downstream workflow path.\\n\\n  \\n **YAML**\\n[code]\\n      - name: demo_conditional\\n        steps:\\n          - name: step_A\\n            type: Bash\\n            configuration:\\n              inputResources:\\n                - name: script_conditional\\n            execution:\\n              onExecute:\\n                - echo \"Executing step_A\"\\n                - printenv\\n         \\n          - name: step_B\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n                - name: step_A\\n            execution:\\n              onExecute:\\n                - echo \"Executing step_B\"\\n                - printenv\\n    \\n          - name: step_C\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n                - name: step_A\\n                  status:\\n                    - failure\\n                    - error\\n                    - timeout\\n            execution:\\n              onExecute:\\n                - echo \"Executing step_C\"\\n                - printenv\\n[/code]\\n##### Example 2\\nIn this example, Step S is triggered if Step Q succeeds and Step R fails. However, if both Step Q and Step R succeed or fail during the run, Step S is not triggered and it is skipped.  \\n **YAML**\\n[code]\\n          - name: step_S\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n                - name: step_Q\\n                  status:\\n                    - success\\n                - name: step_R\\n                  status:\\n                    - failure\\n            execution:\\n              onExecute:\\n                - echo \"Executing step_S\"\\n                - printenv\\n[/code]\\n##### Example 3\\nIn this example, Step O is triggered if Step M succeeds and Step N fails. However, since Step N is not part of the current run, Step O is triggered when Step M succeeds and Step N's status is ignored.  \\n **YAML**\\n[code]\\n          - name: step_O\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n                - name: step_M\\n                  status:\\n                    - success\\n                - name: step_N\\n                  status:\\n                    - failure\\n            execution:\\n              onExecute:\\n                - echo \"Executing step_O\"\\n                - printenv\\n[/code]\\n##### Example 4 - Using Environment Variable\\nThe `step_<inputStepName>_statusName`, which is an environment variable that is automatically made available at runtime, can be used in conjunction with conditional workflows. This `step_<inputStepName>_statusName` environment variable is useful for fetching the status of any input step, especially when working with Jenkins.\\n **YAML**\\n[code]\\n    resources:\\n      - name: script_gh\\n        type: GitRepo\\n        configuration:\\n          path: jfrog/sample-script\\n          gitProvider: myGithub\\n          branches:\\n            include: ^{{gitBranch}}$\\n    \\n    pipelines:     \\n      - name: simple_jenkins_demo\\n        steps:\\n          - name: jenkins\\n            type: Jenkins\\n            configuration:\\n              inputResources:\\n                - name: script_gh\\n              jenkinsJobName: testPipeline\\n              integrations:\\n                - name: myJenkins\\n          \\n          - name: step_A\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n                - name: jenkins\\n                  status:\\n                    - failure\\n                    - error\\n                    - timeout\\n            execution:\\n              onExecute:\\n                - echo \"Executing step_A\"\\n                - if [ $step_jenkins_statusName == \"failure\" ]; then  echo \"Do something\"; fi\\n                - if [ $step_jenkins_statusName == \"error\" ]; then  echo \"Do something else\"; fi\\n         \\n          - name: simple_conditional_B\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n                - name: jenkins\\n                  status:\\n                    - failure\\n                    - error\\n            execution:\\n              onExecute:\\n                - echo \"Executing simple_conditional_B\"\\n                - printenv\\n    \\n[/code]\\n#### allowFailure Examples\\n##### Example 1\\nStep1 is configured for success and step2 for failure. Step2 is allowed to run when step1 fails and the final status of the run is success.\\n[code]\\n    pipelines:\\n      - name: PIPE_9455_Workflow_03\\n        steps:\\n          - name: step1\\n            type: Bash\\n            execution:\\n              onExecute:\\n                - echo 'step1'\\n          - name: step2\\n            type: Bash\\n            configuration:\\n              allowFailure: true\\n              inputSteps:\\n              - name: step1\\n                status:\\n                  - success\\n                  - error\\n                  - failure\\n                  - timeout\\n            execution:\\n              onExecute:\\n                - echo 'success'\\n                - exit 1\\n[/code]\\n##### Example 2\\nStep1 is configured for failure and step2 for success. Step2 is allowed to run when step1 fails and the final status of the run is success.\\n[code]\\n    pipelines:\\n      - name: PIPE_9455_Workflow_05\\n        steps:\\n          - name: step1\\n            type: Bash\\n            configuration:\\n              allowFailure: true\\n            execution:\\n              onExecute:\\n                - echo 'step1'\\n                - exit 1\\n          - name: step2\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n              - name: step1\\n                status:\\n                  - success\\n                  - error\\n                  - failure\\n                  - timeout\\n            execution:\\n              onExecute:\\n                - echo 'success'\\n[/code]\\n##### Example 3\\nStep1 is configured for success and step2 for failure. When triggered, the final status of the run is failure.\\n[code]\\n    pipelines:\\n      - name: PIPE_9455_Workflow_03\\n        steps:\\n          - name: step1\\n            type: Bash\\n            configuration:\\n              allowFailure: true\\n            execution:\\n              onExecute:\\n                - echo 'step1'\\n          - name: step2\\n            type: Bash\\n            configuration:\\n              inputSteps:\\n              - name: step1\\n                status:\\n                  - success\\n                  - error\\n                  - failure\\n                  - timeout\\n            execution:\\n              onExecute:\\n                - echo 'failure'\\n                - exit 1\\n[/code]\\n\\n Document url for reference - https://jfrog.com/help/r/jfrog-pipelines-documentation/pipelines-steps  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.iloc[[0,78,101,234]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have extarcted the data and we can save as CSV\n",
    "final_data.to_csv('./jFrog_pipline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have extarcted our data and we can use `jFrog_pipline.csv` for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
